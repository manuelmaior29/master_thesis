{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "6RtFDqwe_-oh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import playsound\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.models.segmentation.deeplabv3 as dlv3\n",
        "import torchvision.transforms.functional as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import utils\n",
        "import data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Subset\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAHxPFi3_-on"
      },
      "source": [
        "## Training-related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "IlpRZU8c_-on"
      },
      "outputs": [],
      "source": [
        "def validate_epoch(model, val_dataloader, loss_function, num_classes, ignore_label):\n",
        "    model.eval()\n",
        "    batch_losses = []\n",
        "    metrics = {'miou': 0, 'loss': 0}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (inputs, targets) in val_dataloader:\n",
        "            ipts = inputs.to(\"cuda:0\", non_blocking=True)# torch.autograd.Variable(inputs).cuda()\n",
        "            tgts = targets.to(\"cuda:0\", non_blocking=True)# torch.autograd.Variable(targets).cuda()\n",
        "            \n",
        "            preds = model(ipts)['out']\n",
        "            loss = loss_function(preds, tgts.squeeze(1).long())\n",
        "            loss = loss.data.cpu().numpy()\n",
        "            batch_losses += [loss]\n",
        "\n",
        "            preds = torch.argmax(preds.cpu(), dim=1)\n",
        "            tgts = torch.squeeze(targets, dim=1)\n",
        "\n",
        "            miou, ious = utils.measure_performance(preds, tgts, num_classes=num_classes, ignore_label=ignore_label)\n",
        "\n",
        "            metrics['miou'] += miou\n",
        "            metrics['loss'] += loss\n",
        "\n",
        "        metrics['miou'] /= float(len(val_dataloader))\n",
        "        metrics['loss'] /= float(len(val_dataloader))\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "HCkzs16c_-oo"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_dataloader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    batch_losses = []\n",
        "    \n",
        "    for (inputs, targets) in train_dataloader:\n",
        "        ipts = inputs.to(\"cuda:0\", non_blocking=True)# torch.autograd.Variable(inputs).cuda()\n",
        "        tgts = targets.to(\"cuda:0\", non_blocking=True).squeeze(1).long() #tgts = torch.autograd.Variable(targets).cuda().squeeze(1).long()\n",
        "        pred = model(ipts)['out']\n",
        "\n",
        "        loss = loss_function(pred, tgts)\n",
        "        loss_val = loss.data.cpu().numpy()\n",
        "        batch_losses += [loss_val]\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return batch_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "BQIfP6W3_-oo"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataloader, val_dataloader, epochs, loss_function, optimizer, lr_initial, lr_decay, num_classes_val, ignore_label):\n",
        "    model.train()\n",
        "    epoch_train_losses = []\n",
        "    epoch_val_losses = []\n",
        "    epoch_val_mious = []\n",
        "    for epoch in tqdm(range(epochs), desc='Epoch progress'):\n",
        "\n",
        "        # Training phase\n",
        "        batch_train_losses = train_epoch(\n",
        "            model=model, \n",
        "            train_dataloader=train_dataloader,\n",
        "            loss_function=loss_function, \n",
        "            optimizer=optimizer)\n",
        "        \n",
        "        # Validation phase\n",
        "        batch_val_metrics = validate_epoch(\n",
        "            model=model,\n",
        "            val_dataloader=val_dataloader,\n",
        "            loss_function=loss_function,\n",
        "            num_classes=num_classes_val,\n",
        "            ignore_label=ignore_label)\n",
        "\n",
        "        epoch_average_train_loss = np.mean(batch_train_losses)\n",
        "        epoch_train_losses += [epoch_average_train_loss]\n",
        "        epoch_val_losses += [batch_val_metrics['loss']]\n",
        "        epoch_val_mious += [batch_val_metrics['miou']]\n",
        "\n",
        "        print(f'\\n[TRAIN] Epoch average loss: {epoch_average_train_loss:.2f}')\n",
        "        print(f'[VAL] Epoch average loss: {batch_val_metrics[\"loss\"]:.2f}')\n",
        "        print(f'[VAL] Epoch average miou: {batch_val_metrics[\"miou\"]:.2f}\\n')\n",
        "        \n",
        "        if lr_decay:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_initial * ((1.0 - (float(epoch) / float(epochs))) ** 0.9)\n",
        "\n",
        "    return {'epoch_train_losses': epoch_train_losses, 'epoch_val_losses': epoch_val_losses, 'epoch_val_mious': epoch_val_mious}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rc2ZjUV_-oo"
      },
      "source": [
        "## Training configuration loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q45lVAz2_-op",
        "outputId": "ed87cac9-6d68-4a33-9c9c-096a0a092c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data_batch_size': 8,\n",
            " 'data_source': 'real',\n",
            " 'data_subset_size': 160,\n",
            " 'epochs': 8,\n",
            " 'fine_tune': True,\n",
            " 'fine_tune_model_path': 'G:/My Drive/Master IVA/Master '\n",
            "                         'Thesis/Models/20230402_202550/deeplabv3_model.pt',\n",
            " 'ignore_label': 19,\n",
            " 'image_height': 32,\n",
            " 'image_width': 32,\n",
            " 'learning_rate': 0.0005,\n",
            " 'learning_rate_paper_decay': True,\n",
            " 'model_save_path': 'G:/My Drive/Master IVA/Master Thesis/Models',\n",
            " 'val_data_batch_size': 8,\n",
            " 'val_data_subset_size': 48}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "args = {}\n",
        "with open('G:/My Drive/Master IVA/Master Thesis/Configs/train-config-2.json') as json_file:\n",
        "    args = json.load(json_file)\n",
        "pprint.pprint(args)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "l3c4vosw_-op"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "train_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=args[\"data_batch_size\"],\n",
        "                              shuffle=True)\n",
        "val_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                 type=args[\"data_source\"],\n",
        "                                 labels_mapping=None)\n",
        "val_dataset = Subset(val_dataset, indices=range(args[\"val_data_subset_size\"]))\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=args[\"val_data_batch_size\"],\n",
        "                            shuffle=True)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdJK3pF7RRKn",
        "outputId": "91ef22bf-48a8-43c4-acf3-6e9701143f6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training dataset norm. params. comp. progress: 100%|██████████| 20/20 [00:15<00:00,  1.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset 'mean':tensor([0.2240, 0.2647, 0.2249])\n",
            "Train dataset 'std deviation':tensor([0.1361, 0.1463, 0.1413])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation dataset norm. params. comp. progress:   0%|          | 0/6 [00:00<?, ?it/s]C:\\Users\\Manuel\\AppData\\Local\\Temp\\ipykernel_7296\\3029786214.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_inputs_tensor = torch.tensor(val_inputs)\n",
            "Validation dataset norm. params. comp. progress: 100%|██████████| 6/6 [00:04<00:00,  1.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation dataset 'mean':tensor([0.3329, 0.3683, 0.3279])\n",
            "Validation dataset 'std deviation':tensor([0.2135, 0.2125, 0.2075])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_pixel_sum = torch.tensor([0.0, 0.0, 0.0])\n",
        "train_pixel_sum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "for train_inputs, _ in tqdm(train_dataloader, desc='Training dataset norm. params. comp. progress'):\n",
        "    train_pixel_sum += train_inputs.sum(axis = [0, 2, 3])\n",
        "    train_pixel_sum_sq += (train_inputs ** 2).sum(axis = [0, 2, 3])\n",
        "\n",
        "train_pixel_count = args[\"data_subset_size\"] * args[\"image_width\"] * args[\"image_height\"]\n",
        "train_mean = train_pixel_sum / train_pixel_count\n",
        "train_variance = (train_pixel_sum_sq / train_pixel_count) - (train_mean ** 2)\n",
        "train_std = torch.sqrt(train_variance)\n",
        "\n",
        "print(f'Train dataset \\'mean\\':{train_mean}')\n",
        "print(f'Train dataset \\'std deviation\\':{train_std}')\n",
        "\n",
        "val_pixel_sum = torch.tensor([0.0, 0.0, 0.0])\n",
        "val_pixel_sum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "for val_inputs, _ in tqdm(val_dataloader, desc='Validation dataset norm. params. comp. progress'):\n",
        "    val_inputs_tensor = torch.tensor(val_inputs)\n",
        "    val_pixel_sum += val_inputs_tensor.sum(axis = [0, 2, 3])\n",
        "    val_pixel_sum_sq += (val_inputs_tensor ** 2).sum(axis = [0, 2, 3])\n",
        "\n",
        "val_pixel_count = args[\"val_data_subset_size\"] * args[\"image_width\"] * args[\"image_height\"]\n",
        "val_mean = val_pixel_sum / val_pixel_count\n",
        "val_variance = (val_pixel_sum_sq / val_pixel_count) - (val_mean ** 2)\n",
        "val_std = torch.sqrt(val_variance)\n",
        "\n",
        "print(f'Validation dataset \\'mean\\':{val_mean}')\n",
        "print(f'Validation dataset \\'std deviation\\':{val_std}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "M8kQ9HkVRRKo"
      },
      "outputs": [],
      "source": [
        "train_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.Normalize(mean=list(train_mean), std=list(train_std))]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=args[\"data_batch_size\"],\n",
        "                              shuffle=True, pin_memory=True, num_workers=4)\n",
        "val_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.Normalize(mean=list(val_mean), std=list(val_std))]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]), \n",
        "                                 type=args[\"data_source\"],\n",
        "                                 labels_mapping=None)\n",
        "val_dataset = Subset(val_dataset, indices=range(args[\"val_data_subset_size\"]))\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=args[\"val_data_batch_size\"],\n",
        "                            shuffle=True, pin_memory=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQIRQ39o_-op"
      },
      "source": [
        "## Training preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhR4VbF2_-op",
        "outputId": "f4675100-719a-425f-a436-2f27f3e405c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model to device.\n"
          ]
        }
      ],
      "source": [
        "model = dlv3.deeplabv3_resnet50(weights=None, output_stride=16, progress=True, num_classes=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys()))\n",
        "if args[\"fine_tune\"]:\n",
        "    model.load_state_dict(torch.load(args[\"fine_tune_model_path\"]))\n",
        "    for name, param in model.backbone.named_parameters():\n",
        "        if 'layer1' in name or 'layer2' in name or 'layer3' in name or 'layer4' in name or 'layer5' in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('Loaded model to device.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "Ud3YI0lQ_-oq"
      },
      "outputs": [],
      "source": [
        "params = utils.add_weight_decay(model, l2_value=0.0001)\n",
        "optimizer = torch.optim.Adam(params=params, lr=args[\"learning_rate\"])\n",
        "loss_function = nn.CrossEntropyLoss()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VKyjxND_-oq",
        "outputId": "ac9f3984-73d5-47ed-9f42-a93c40938b73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   0%|          | 0/8 [00:04<?, ?it/s]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not builtin_function_or_method",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Manuel\\Projects\\GitHub_Repositories\\master_thesis\\python_scripts_semseg\\train.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mcudnn\u001b[39m.\u001b[39mbenchmark \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_metrics \u001b[39m=\u001b[39m train(model\u001b[39m=\u001b[39;49mmodel, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m       train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m       val_dataloader\u001b[39m=\u001b[39;49mval_dataloader, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m       epochs\u001b[39m=\u001b[39;49margs[\u001b[39m\"\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m\"\u001b[39;49m], \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m       loss_function\u001b[39m=\u001b[39;49mloss_function, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m       optimizer\u001b[39m=\u001b[39;49moptimizer, \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m       lr_initial\u001b[39m=\u001b[39;49margs[\u001b[39m\"\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m       lr_decay\u001b[39m=\u001b[39;49margs[\u001b[39m\"\u001b[39;49m\u001b[39mlearning_rate_paper_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m       num_classes_val\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(data\u001b[39m.\u001b[39;49mSemanticLabelMapper\u001b[39m.\u001b[39;49mID_TO_STRING[\u001b[39m'\u001b[39;49m\u001b[39mcommon\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mkeys()),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m       ignore_label\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
            "\u001b[1;32mc:\\Users\\Manuel\\Projects\\GitHub_Repositories\\master_thesis\\python_scripts_semseg\\train.ipynb Cell 16\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, val_dataloader, epochs, loss_function, optimizer, lr_initial, lr_decay, num_classes_val, ignore_label)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m epoch_val_mious \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch progress\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Training phase\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     batch_train_losses \u001b[39m=\u001b[39m train_epoch(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         model\u001b[39m=\u001b[39;49mmodel, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         loss_function\u001b[39m=\u001b[39;49mloss_function, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# Validation phase\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     batch_val_metrics \u001b[39m=\u001b[39m validate_epoch(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         val_dataloader\u001b[39m=\u001b[39mval_dataloader,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         loss_function\u001b[39m=\u001b[39mloss_function,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         num_classes\u001b[39m=\u001b[39mnum_classes_val,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         ignore_label\u001b[39m=\u001b[39mignore_label)\n",
            "\u001b[1;32mc:\\Users\\Manuel\\Projects\\GitHub_Repositories\\master_thesis\\python_scripts_semseg\\train.ipynb Cell 16\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, train_dataloader, loss_function, optimizer)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tgts \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda:0\u001b[39m\u001b[39m\"\u001b[39m, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mlong \u001b[39m#tgts = torch.autograd.Variable(targets).cuda().squeeze(1).long()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m pred \u001b[39m=\u001b[39m model(ipts)[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(pred, tgts)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss_val \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X21sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m batch_losses \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [loss_val]\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1164\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1164\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1165\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1166\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3014\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3012\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3013\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3014\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
            "\u001b[1;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'target' (position 2) must be Tensor, not builtin_function_or_method"
          ]
        }
      ],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "train_metrics = train(model=model, \n",
        "      train_dataloader=train_dataloader, \n",
        "      val_dataloader=val_dataloader, \n",
        "      epochs=args[\"epochs\"], \n",
        "      loss_function=loss_function, \n",
        "      optimizer=optimizer, \n",
        "      lr_initial=args[\"learning_rate\"],\n",
        "      lr_decay=args[\"learning_rate_paper_decay\"],\n",
        "      num_classes_val=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys()),\n",
        "      ignore_label=None)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train report generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sEVMrQz_-oq"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "current_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_save_path = f'{args[\"model_save_path\"]}/{current_time}'\n",
        "os.mkdir(model_save_path)\n",
        "\n",
        "plt.plot(train_metrics['epoch_train_losses'], label='Train loss', color='blue') \n",
        "plt.plot(train_metrics['epoch_val_losses'], label='Validation loss', color='yellow') \n",
        "plt.xlabel('Epoch') \n",
        "plt.ylabel('Loss') \n",
        "plt.xticks(range(0, args['epochs']))\n",
        "plt.title('Loss over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/loss_over_epochs.jpg', dpi=300)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(train_metrics['epoch_val_mious'], label='Validation mIoU', color='green') \n",
        "plt.xlabel('Epoch') \n",
        "plt.ylabel('mIoU') \n",
        "plt.xticks(range(0, args['epochs']))\n",
        "plt.title('mIoU over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/iou_over_epochs.jpg', dpi=300)\n",
        "\n",
        "train_std = train_std.tolist()\n",
        "train_mean = train_mean.tolist()\n",
        "\n",
        "eval_args = {'model_load_folder_path': model_save_path,\n",
        "             'train_std': train_std,\n",
        "             'train_mean': train_mean,\n",
        "             'data_source': args['data_source'],\n",
        "             'test_subset_size': 300,\n",
        "             'test_batch_size': 4,\n",
        "             'ignore_label': args['ignore_label'],\n",
        "             'image_width': args['image_width'],\n",
        "             'image_height': args['image_height']}\n",
        "eval_args = json.dumps(eval_args, indent=4)\n",
        "with open(file=f'{model_save_path}/eval-config.json', mode='w') as f:\n",
        "    f.write(eval_args)\n",
        "    \n",
        "args = json.dumps(args, indent=4)\n",
        "with open(file=f'{model_save_path}/train_config.json', mode='w') as f:\n",
        "    f.write(args)\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), f'{model_save_path}/deeplabv3_model.pt')\n",
        "playsound.playsound('finished.mp3')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
