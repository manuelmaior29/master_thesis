{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6RtFDqwe_-oh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.models.segmentation.deeplabv3 as dlv3\n",
        "import torchvision.transforms.functional as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import utils\n",
        "import data\n",
        "import copy\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAHxPFi3_-on"
      },
      "source": [
        "## Training-related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IlpRZU8c_-on"
      },
      "outputs": [],
      "source": [
        "def validate_epoch(model, device, val_dataloader, loss_function, num_classes, ignore_label):\n",
        "    model.eval()\n",
        "    metrics = {'miou': 0, 'ious': np.zeros(shape=(num_classes,), dtype=np.float64), 'loss': 0}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (inputs, targets) in val_dataloader:\n",
        "            ipts = inputs.to(device, non_blocking=True)# torch.autograd.Variable(inputs).cuda()\n",
        "            tgts = targets.to(device, non_blocking=True)# torch.autograd.Variable(targets).cuda()\n",
        "            \n",
        "            preds = model(ipts)['out']\n",
        "            loss = loss_function(preds, tgts.squeeze(1).long())\n",
        "            loss_val = loss.item()\n",
        "\n",
        "            preds = torch.argmax(preds.cpu(), dim=1)\n",
        "            tgts = torch.squeeze(targets, dim=1)\n",
        "\n",
        "            miou, ious = utils.measure_performance(preds, tgts, num_classes=num_classes, ignore_label=ignore_label)\n",
        "\n",
        "            metrics['ious'] += ious\n",
        "            metrics['miou'] += miou\n",
        "            metrics['loss'] += loss_val\n",
        "\n",
        "        metrics['ious'] /= float(len(val_dataloader))\n",
        "        metrics['miou'] /= float(len(val_dataloader))\n",
        "        metrics['loss'] /= float(len(val_dataloader))\n",
        "        \n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HCkzs16c_-oo"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, device, scaler, train_dataloader, loss_function, num_classes, optimizer, compute_iou=False):\n",
        "    model.train()\n",
        "    metrics = {'miou': 0, 'ious': np.zeros(shape=(num_classes,), dtype=np.float64), 'loss': 0}\n",
        "    \n",
        "    for (inputs, targets) in train_dataloader:\n",
        "        ipts = inputs.to(device, non_blocking=True)# torch.autograd.Variable(inputs).cuda()\n",
        "        tgts = targets.to(device, non_blocking=True).squeeze(1).long() #tgts = torch.autograd.Variable(targets).cuda().squeeze(1).long()\n",
        "        \n",
        "        pred = model(ipts)['out']\n",
        "        with torch.cuda.amp.autocast():\n",
        "            loss = loss_function(pred, tgts)\n",
        "            loss_val = loss.item()\n",
        "            metrics['loss'] += loss_val\n",
        "\n",
        "        # Measure miou on training\n",
        "        if compute_iou:\n",
        "            pred = torch.argmax(pred.cpu(), dim=1)\n",
        "            tgts = torch.squeeze(targets, dim=1)\n",
        "            miou, ious = utils.measure_performance(pred, tgts, num_classes=num_classes, ignore_label=None)\n",
        "            metrics['ious'] += ious\n",
        "            metrics['miou'] += miou\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        scaler.scale(loss).backward() # loss.backward()\n",
        "        scaler.step(optimizer) #optimizer.step()\n",
        "        scaler.update()\n",
        "    \n",
        "    if compute_iou:\n",
        "        metrics['ious'] /= float(len(train_dataloader))\n",
        "        metrics['miou'] /= float(len(train_dataloader))\n",
        "\n",
        "    metrics['loss'] /= float(len(train_dataloader))\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BQIfP6W3_-oo"
      },
      "outputs": [],
      "source": [
        "def train(model, device, scaler, train_dataloader, val_dataloader, epochs, loss_function, optimizer, lr_initial, lr_decay, num_classes_val, ignore_label):\n",
        "    model.train()\n",
        "    compute_iou = False\n",
        "\n",
        "    epoch_train_losses = []\n",
        "    epoch_train_mious = []\n",
        "    epoch_val_losses = []\n",
        "    epoch_val_mious = []\n",
        "    epoch_val_ious = []\n",
        "\n",
        "    best_model = copy.deepcopy(model.state_dict())\n",
        "    best_val_miou = 0\n",
        "    \n",
        "    for epoch in tqdm(range(epochs), desc='Epoch progress'):\n",
        "\n",
        "        # Training phase\n",
        "        batch_train_metrics = train_epoch(\n",
        "            model=model, \n",
        "            device=device,\n",
        "            scaler=scaler,\n",
        "            train_dataloader=train_dataloader,\n",
        "            loss_function=loss_function,\n",
        "            num_classes=num_classes_val,\n",
        "            optimizer=optimizer,\n",
        "            compute_iou=compute_iou)\n",
        "        \n",
        "        # Validation phase\n",
        "        batch_val_metrics = validate_epoch(\n",
        "            model=model,\n",
        "            device=device,\n",
        "            val_dataloader=val_dataloader,\n",
        "            loss_function=loss_function,\n",
        "            num_classes=num_classes_val,\n",
        "            ignore_label=ignore_label)\n",
        "\n",
        "        epoch_train_losses += [batch_train_metrics[\"loss\"]]\n",
        "        epoch_val_losses += [batch_val_metrics['loss']]\n",
        "        epoch_val_mious += [batch_val_metrics['miou']]\n",
        "        epoch_val_ious += [batch_val_metrics['ious'].tolist()]\n",
        "\n",
        "        print(f'\\n[TRAIN] Epoch average loss: {batch_train_metrics[\"loss\"]:.4f}')\n",
        "        if compute_iou:\n",
        "            epoch_train_mious += [batch_train_metrics[\"miou\"]]\n",
        "            print(f'[TRAIN] Epoch average miou: {100 * batch_train_metrics[\"miou\"]:.2f}%')\n",
        "        print(f'[VAL] Epoch average loss: {batch_val_metrics[\"loss\"]:.4f}')\n",
        "        print(f'[VAL] Epoch average miou: {100 * batch_val_metrics[\"miou\"]:.2f}%')\n",
        "        \n",
        "        if lr_decay:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_initial * ((1.0 - (float(epoch) / float(epochs))) ** 0.9)\n",
        "\n",
        "        if epoch == 0 or batch_val_metrics['miou'] > best_val_miou:\n",
        "            best_val_miou = batch_val_metrics['miou']\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            print('\\033[96m[MODEL] Checkpoint saved.\\n\\033[0m')\n",
        "\n",
        "    model.load_state_dict(best_model)\n",
        "    return model, {'epoch_train_losses': epoch_train_losses, 'epoch_val_losses': epoch_val_losses, 'epoch_val_mious': epoch_val_mious, 'epoch_val_ious': epoch_val_ious}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rc2ZjUV_-oo"
      },
      "source": [
        "## Training configuration loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q45lVAz2_-op",
        "outputId": "ed87cac9-6d68-4a33-9c9c-096a0a092c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data_batch_size': 2,\n",
            " 'data_source': 'real',\n",
            " 'data_subset_size': 2,\n",
            " 'epochs': 200,\n",
            " 'fine_tune': False,\n",
            " 'fine_tune_model_path': 'G:/My Drive/Master IVA/Master '\n",
            "                         'Thesis/Models/20230403_210427/deeplabv3_model.pt',\n",
            " 'ignore_label': 19,\n",
            " 'image_height': 256,\n",
            " 'image_width': 256,\n",
            " 'learning_rate': 0.001,\n",
            " 'learning_rate_paper_decay': True,\n",
            " 'model_save_path': 'G:/My Drive/Master IVA/Master Thesis/Models',\n",
            " 'val_data_batch_size': 2,\n",
            " 'val_data_subset_size': 2,\n",
            " 'weigh_loss': True}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "args = {}\n",
        "with open('G:/My Drive/Master IVA/Master Thesis/Configs/train-config-2.json') as json_file:\n",
        "    args = json.load(json_file)\n",
        "pprint.pprint(args)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "l3c4vosw_-op"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "train_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=args[\"data_batch_size\"],\n",
        "                              shuffle=True)\n",
        "val_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                 type=args[\"data_source\"],\n",
        "                                 labels_mapping=None)\n",
        "val_dataset = Subset(val_dataset, indices=range(args[\"val_data_subset_size\"]))\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=args[\"val_data_batch_size\"],\n",
        "                            shuffle=True)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdJK3pF7RRKn",
        "outputId": "91ef22bf-48a8-43c4-acf3-6e9701143f6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training dataset norm. params. comp. progress:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1024, 2048])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training dataset norm. params. comp. progress: 100%|██████████| 1/1 [00:00<00:00,  4.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1024, 2048])\n",
            "Train dataset 'mean':tensor([0.2328, 0.2736, 0.2284])\n",
            "Train dataset 'std deviation':tensor([0.1093, 0.1176, 0.1104])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation dataset norm. params. comp. progress:   0%|          | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1024, 2048])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Manuel\\AppData\\Local\\Temp\\ipykernel_51944\\3029786214.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_inputs_tensor = torch.tensor(val_inputs)\n",
            "Validation dataset norm. params. comp. progress: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1024, 2048])\n",
            "Validation dataset 'mean':tensor([0.3471, 0.3726, 0.3261])\n",
            "Validation dataset 'std deviation':tensor([0.2418, 0.2403, 0.2323])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_pixel_sum = torch.tensor([0.0, 0.0, 0.0])\n",
        "train_pixel_sum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "for train_inputs, _ in tqdm(train_dataloader, desc='Training dataset norm. params. comp. progress'):\n",
        "    train_pixel_sum += train_inputs.sum(axis = [0, 2, 3])\n",
        "    train_pixel_sum_sq += (train_inputs ** 2).sum(axis = [0, 2, 3])\n",
        "\n",
        "train_pixel_count = args[\"data_subset_size\"] * args[\"image_width\"] * args[\"image_height\"]\n",
        "train_mean = train_pixel_sum / train_pixel_count\n",
        "train_variance = (train_pixel_sum_sq / train_pixel_count) - (train_mean ** 2)\n",
        "train_std = torch.sqrt(train_variance)\n",
        "\n",
        "print(f'Train dataset \\'mean\\':{train_mean}')\n",
        "print(f'Train dataset \\'std deviation\\':{train_std}')\n",
        "\n",
        "val_pixel_sum = torch.tensor([0.0, 0.0, 0.0])\n",
        "val_pixel_sum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "for val_inputs, _ in tqdm(val_dataloader, desc='Validation dataset norm. params. comp. progress'):\n",
        "    val_inputs_tensor = torch.tensor(val_inputs)\n",
        "    val_pixel_sum += val_inputs_tensor.sum(axis = [0, 2, 3])\n",
        "    val_pixel_sum_sq += (val_inputs_tensor ** 2).sum(axis = [0, 2, 3])\n",
        "\n",
        "val_pixel_count = args[\"val_data_subset_size\"] * args[\"image_width\"] * args[\"image_height\"]\n",
        "val_mean = val_pixel_sum / val_pixel_count\n",
        "val_variance = (val_pixel_sum_sq / val_pixel_count) - (val_mean ** 2)\n",
        "val_std = torch.sqrt(val_variance)\n",
        "\n",
        "print(f'Validation dataset \\'mean\\':{val_mean}')\n",
        "print(f'Validation dataset \\'std deviation\\':{val_std}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "M8kQ9HkVRRKo"
      },
      "outputs": [],
      "source": [
        "# Datasets\n",
        "## Train dataset\n",
        "train_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.Normalize(mean=list(train_mean), std=list(train_std)),\n",
        "                                                                                 torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "\n",
        "## Train dataset (aug)\n",
        "train_dataset_aug = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.Normalize(mean=list(train_mean), std=list(train_std)),\n",
        "                                                                                 torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset_aug = Subset(train_dataset_aug, indices=range(args[\"data_subset_size\"]))\n",
        "\n",
        "## Val dataset\n",
        "val_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.Normalize(mean=list(val_mean), std=list(val_std)),\n",
        "                                                                               torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.RandomHorizontalFlip(p=1.0)]), \n",
        "                                 type=args[\"data_source\"],\n",
        "                                 labels_mapping=None)\n",
        "val_dataset = Subset(val_dataset, indices=range(args[\"val_data_subset_size\"]))\n",
        "\n",
        "## Val dataset (aug)\n",
        "val_dataset_aug = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.Normalize(mean=list(val_mean), std=list(val_std)),\n",
        "                                                                               torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.RandomHorizontalFlip(p=1.0)]), \n",
        "                                 type=args[\"data_source\"],\n",
        "                                 labels_mapping=None)\n",
        "val_dataset_aug = Subset(val_dataset_aug, indices=range(args[\"val_data_subset_size\"]))\n",
        "\n",
        "# Concatenate original + aug datasets\n",
        "train_dataset_concatenated = ConcatDataset([train_dataset, train_dataset_aug])\n",
        "val_dataset_concatenated = ConcatDataset([val_dataset, val_dataset_aug])\n",
        "\n",
        "# Dataloaders\n",
        "train_dataloader = DataLoader(dataset=train_dataset_concatenated,\n",
        "                              batch_size=args[\"data_batch_size\"],\n",
        "                              shuffle=True, pin_memory=True, num_workers=4)\n",
        "val_dataloader = DataLoader(dataset=val_dataset_concatenated,\n",
        "                            batch_size=args[\"val_data_batch_size\"],\n",
        "                            shuffle=True, pin_memory=True, num_workers=4)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zQIRQ39o_-op"
      },
      "source": [
        "## Training preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhR4VbF2_-op",
        "outputId": "f4675100-719a-425f-a436-2f27f3e405c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model to device.\n"
          ]
        }
      ],
      "source": [
        "model = dlv3.deeplabv3_resnet50(weights=None, output_stride=16, progress=True, num_classes=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys()))\n",
        "if args[\"fine_tune\"]:\n",
        "    model.load_state_dict(torch.load(args[\"fine_tune_model_path\"]))\n",
        "    for name, param in model.backbone.named_parameters():\n",
        "        if 'layer1' in name or 'layer2' in name or 'layer3' in name or 'layer4' in name or 'layer5' in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('Loaded model to device.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ud3YI0lQ_-oq"
      },
      "outputs": [],
      "source": [
        "params = utils.add_weight_decay(model, l2_value=0.0001)\n",
        "optimizer = torch.optim.Adam(params=params, lr=args[\"learning_rate\"])\n",
        "\n",
        "class_weights = None\n",
        "if args['weighted_loss']:\n",
        "    if args['data_source'] == 'synthetic':\n",
        "        class_weights = [\n",
        "                (100 - 34.547) / 100,\n",
        "                (100 - 7.025) / 100,\n",
        "                (100 - 16.881) / 100,\n",
        "                (100 - 1.842) / 100,\n",
        "                (100 - 0.698) / 100,\n",
        "                (100 - 0.109) / 100,\n",
        "                (100 - 0.139) / 100,\n",
        "                (100 - 13.758) / 100,\n",
        "                (100 - 1.368) / 100,\n",
        "                (100 - 0.925) / 100,\n",
        "                (100 - 0.104) / 100,\n",
        "                (100 - 3.03) / 100,\n",
        "                (100 - 1.504) / 100,\n",
        "                (100 - 0.789) / 100,\n",
        "                (100 - 0.087) / 100,\n",
        "                (100 - 0.017) / 100,\n",
        "                (100 - 17.177) / 100,\n",
        "            ]\n",
        "    elif args['data_source'] == 'real':\n",
        "        class_weights = [\n",
        "                (100 - 32.635) / 100,\n",
        "                (100 - 5.39) / 100,\n",
        "                (100 - 20.203) / 100,\n",
        "                (100 - 0.58) / 100,\n",
        "                (100 - 0.777) / 100,\n",
        "                (100 - 0.184) / 100,\n",
        "                (100 - 0.488) / 100,\n",
        "                (100 - 14.104) / 100,\n",
        "                (100 - 1.021) / 100,\n",
        "                (100 - 1.08) / 100,\n",
        "                (100 - 0.12) / 100,\n",
        "                (100 - 6.195) / 100,\n",
        "                (100 - 0.237) / 100,\n",
        "                (100 - 0.208) / 100,\n",
        "                (100 - 0.087) / 100,\n",
        "                (100 - 0.367) / 100,\n",
        "                (100 - 16.324) / 100,\n",
        "            ]\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VKyjxND_-oq",
        "outputId": "ac9f3984-73d5-47ed-9f42-a93c40938b73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   0%|          | 1/200 [00:06<23:00,  6.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 2.6544\n",
            "[VAL] Epoch average loss: 1.9040\n",
            "[VAL] Epoch average miou: 7.22%\n",
            "\u001b[96m[MODEL] Checkpoint saved.\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   1%|          | 2/200 [00:13<21:51,  6.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 1.5438\n",
            "[VAL] Epoch average loss: 2.1740\n",
            "[VAL] Epoch average miou: 9.93%\n",
            "\u001b[96m[MODEL] Checkpoint saved.\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   2%|▏         | 3/200 [00:19<21:42,  6.61s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 1.1830\n",
            "[VAL] Epoch average loss: 7.3348\n",
            "[VAL] Epoch average miou: 9.95%\n",
            "\u001b[96m[MODEL] Checkpoint saved.\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   2%|▏         | 4/200 [00:26<21:38,  6.63s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.8591\n",
            "[VAL] Epoch average loss: 12.6865\n",
            "[VAL] Epoch average miou: 9.36%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   2%|▎         | 5/200 [00:33<21:25,  6.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.6215\n",
            "[VAL] Epoch average loss: 2.6411\n",
            "[VAL] Epoch average miou: 11.52%\n",
            "\u001b[96m[MODEL] Checkpoint saved.\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   3%|▎         | 6/200 [00:39<21:05,  6.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.6245\n",
            "[VAL] Epoch average loss: 1.7801\n",
            "[VAL] Epoch average miou: 12.53%\n",
            "\u001b[96m[MODEL] Checkpoint saved.\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   4%|▎         | 7/200 [00:46<20:59,  6.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.4968\n",
            "[VAL] Epoch average loss: 1.6937\n",
            "[VAL] Epoch average miou: 13.45%\n",
            "\u001b[96m[MODEL] Checkpoint saved.\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   4%|▍         | 8/200 [00:52<20:49,  6.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.4915\n",
            "[VAL] Epoch average loss: 1.6014\n",
            "[VAL] Epoch average miou: 13.58%\n",
            "\u001b[96m[MODEL] Checkpoint saved.\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   4%|▍         | 9/200 [00:58<20:34,  6.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.4610\n",
            "[VAL] Epoch average loss: 1.5062\n",
            "[VAL] Epoch average miou: 13.21%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   5%|▌         | 10/200 [01:05<20:28,  6.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.4136\n",
            "[VAL] Epoch average loss: 1.4979\n",
            "[VAL] Epoch average miou: 13.73%\n",
            "\u001b[96m[MODEL] Checkpoint saved.\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   6%|▌         | 11/200 [01:11<20:15,  6.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.3907\n",
            "[VAL] Epoch average loss: 1.4582\n",
            "[VAL] Epoch average miou: 13.84%\n",
            "\u001b[96m[MODEL] Checkpoint saved.\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   6%|▌         | 12/200 [01:18<20:16,  6.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.3689\n",
            "[VAL] Epoch average loss: 1.4263\n",
            "[VAL] Epoch average miou: 14.13%\n",
            "\u001b[96m[MODEL] Checkpoint saved.\n",
            "\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   6%|▋         | 13/200 [01:24<20:14,  6.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.3873\n",
            "[VAL] Epoch average loss: 1.4117\n",
            "[VAL] Epoch average miou: 14.05%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   7%|▋         | 14/200 [01:31<20:00,  6.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.3444\n",
            "[VAL] Epoch average loss: 1.4068\n",
            "[VAL] Epoch average miou: 13.72%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   8%|▊         | 15/200 [01:37<20:08,  6.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.3329\n",
            "[VAL] Epoch average loss: 1.3971\n",
            "[VAL] Epoch average miou: 12.78%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   8%|▊         | 16/200 [01:44<19:57,  6.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.3543\n",
            "[VAL] Epoch average loss: 1.4046\n",
            "[VAL] Epoch average miou: 12.15%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   8%|▊         | 17/200 [01:51<20:08,  6.60s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.3203\n",
            "[VAL] Epoch average loss: 1.3816\n",
            "[VAL] Epoch average miou: 12.42%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   9%|▉         | 18/200 [01:57<19:57,  6.58s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.3074\n",
            "[VAL] Epoch average loss: 1.3508\n",
            "[VAL] Epoch average miou: 12.07%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  10%|▉         | 19/200 [02:04<19:44,  6.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2981\n",
            "[VAL] Epoch average loss: 1.3390\n",
            "[VAL] Epoch average miou: 12.52%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  10%|█         | 20/200 [02:10<19:34,  6.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2956\n",
            "[VAL] Epoch average loss: 1.3279\n",
            "[VAL] Epoch average miou: 12.55%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  10%|█         | 21/200 [02:17<19:27,  6.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2858\n",
            "[VAL] Epoch average loss: 1.3133\n",
            "[VAL] Epoch average miou: 11.95%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  11%|█         | 22/200 [02:23<19:23,  6.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2798\n",
            "[VAL] Epoch average loss: 1.2944\n",
            "[VAL] Epoch average miou: 11.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  12%|█▏        | 23/200 [02:30<19:18,  6.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.3078\n",
            "[VAL] Epoch average loss: 1.2895\n",
            "[VAL] Epoch average miou: 12.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  12%|█▏        | 24/200 [02:36<19:03,  6.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2744\n",
            "[VAL] Epoch average loss: 1.2855\n",
            "[VAL] Epoch average miou: 11.78%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  12%|█▎        | 25/200 [02:43<18:50,  6.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2939\n",
            "[VAL] Epoch average loss: 1.2732\n",
            "[VAL] Epoch average miou: 11.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  13%|█▎        | 26/200 [02:49<18:42,  6.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2638\n",
            "[VAL] Epoch average loss: 1.2756\n",
            "[VAL] Epoch average miou: 12.14%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  14%|█▎        | 27/200 [02:55<18:38,  6.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2833\n",
            "[VAL] Epoch average loss: 1.2834\n",
            "[VAL] Epoch average miou: 11.35%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  14%|█▍        | 28/200 [03:02<18:33,  6.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2761\n",
            "[VAL] Epoch average loss: 1.2885\n",
            "[VAL] Epoch average miou: 11.43%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  14%|█▍        | 29/200 [03:08<18:22,  6.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2539\n",
            "[VAL] Epoch average loss: 1.2824\n",
            "[VAL] Epoch average miou: 11.46%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  15%|█▌        | 30/200 [03:15<18:14,  6.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2513\n",
            "[VAL] Epoch average loss: 1.2916\n",
            "[VAL] Epoch average miou: 12.15%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  16%|█▌        | 31/200 [03:21<17:53,  6.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2466\n",
            "[VAL] Epoch average loss: 1.3193\n",
            "[VAL] Epoch average miou: 11.29%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  16%|█▌        | 32/200 [03:28<18:13,  6.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2594\n",
            "[VAL] Epoch average loss: 1.3439\n",
            "[VAL] Epoch average miou: 11.20%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  16%|█▋        | 33/200 [03:34<18:07,  6.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2414\n",
            "[VAL] Epoch average loss: 1.3383\n",
            "[VAL] Epoch average miou: 11.83%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  17%|█▋        | 34/200 [03:41<17:58,  6.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2369\n",
            "[VAL] Epoch average loss: 1.3403\n",
            "[VAL] Epoch average miou: 11.90%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  18%|█▊        | 35/200 [03:47<17:52,  6.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2512\n",
            "[VAL] Epoch average loss: 1.3718\n",
            "[VAL] Epoch average miou: 11.96%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  18%|█▊        | 36/200 [03:54<17:44,  6.49s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2353\n",
            "[VAL] Epoch average loss: 1.3802\n",
            "[VAL] Epoch average miou: 11.62%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  18%|█▊        | 37/200 [04:00<17:39,  6.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2450\n",
            "[VAL] Epoch average loss: 1.3641\n",
            "[VAL] Epoch average miou: 11.48%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  19%|█▉        | 38/200 [04:07<17:29,  6.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2411\n",
            "[VAL] Epoch average loss: 1.3653\n",
            "[VAL] Epoch average miou: 11.99%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  20%|█▉        | 39/200 [04:13<17:24,  6.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2289\n",
            "[VAL] Epoch average loss: 1.3951\n",
            "[VAL] Epoch average miou: 11.55%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  20%|██        | 40/200 [04:20<17:27,  6.55s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.2245\n",
            "[VAL] Epoch average loss: 1.4014\n",
            "[VAL] Epoch average miou: 12.11%\n"
          ]
        }
      ],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "model, train_metrics = train(model=model,\n",
        "                             device=device,\n",
        "                             scaler=scaler,\n",
        "                             train_dataloader=train_dataloader, \n",
        "                             val_dataloader=val_dataloader, \n",
        "                             epochs=args[\"epochs\"], \n",
        "                             loss_function=loss_function, \n",
        "                             optimizer=optimizer, \n",
        "                             lr_initial=args[\"learning_rate\"],\n",
        "                             lr_decay=args[\"learning_rate_paper_decay\"],\n",
        "                             num_classes_val=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys()),\n",
        "                             ignore_label=None)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train report generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sEVMrQz_-oq"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "current_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_save_path = f'{args[\"model_save_path\"]}/{current_time}'\n",
        "os.mkdir(model_save_path)\n",
        "\n",
        "matplotlib.rcParams.update({'font.size': 6})\n",
        "\n",
        "plt.plot(train_metrics['epoch_train_losses'], label='Train loss', color='blue') \n",
        "plt.plot(train_metrics['epoch_val_losses'], label='Validation loss', color='yellow') \n",
        "plt.xlabel('Epoch') \n",
        "plt.xticks(ticks=np.arange(0, args['epochs']))\n",
        "plt.ylabel('Loss') \n",
        "plt.title('Loss over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/loss_over_epochs.jpg', dpi=1200)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(train_metrics['epoch_val_mious'], label='Validation mIoU', color='green') \n",
        "plt.xlabel('Epoch') \n",
        "plt.xticks(ticks=np.arange(0, args['epochs']))\n",
        "plt.ylabel('mIoU') \n",
        "plt.yticks(np.arange(0.0, 1.1, 0.1))\n",
        "plt.title('mIoU over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/iou_over_epochs.jpg', dpi=1200)\n",
        "\n",
        "train_std = train_std.tolist()\n",
        "train_mean = train_mean.tolist()\n",
        "\n",
        "eval_args = {'model_load_folder_path': model_save_path,\n",
        "             'train_std': train_std,\n",
        "             'train_mean': train_mean,\n",
        "             'data_source': \"real\",\n",
        "             'test_subset_size': 300,\n",
        "             'test_batch_size': 4,\n",
        "             'ignore_label': args['ignore_label'],\n",
        "             'image_width': args['image_width'],\n",
        "             'image_height': args['image_height']}\n",
        "eval_args = json.dumps(eval_args, indent=4)\n",
        "with open(file=f'{model_save_path}/eval-config.json', mode='w') as f:\n",
        "    f.write(eval_args)\n",
        "    \n",
        "args = json.dumps(args, indent=4)\n",
        "with open(file=f'{model_save_path}/train_config.json', mode='w') as f:\n",
        "    f.write(args)\n",
        "\n",
        "train_metrics = json.dumps(train_metrics, indent=4)\n",
        "with open(file=f'{model_save_path}/train_metrics.json', mode='w') as f:\n",
        "    f.write(train_metrics)\n",
        "\n",
        "torch.save(model.state_dict(), f'{model_save_path}/deeplabv3_model.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
