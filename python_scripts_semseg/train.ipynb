{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6RtFDqwe_-oh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import playsound\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.models.segmentation.deeplabv3 as dlv3\n",
        "import torchvision.transforms.functional as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import utils\n",
        "import data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Subset\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAHxPFi3_-on"
      },
      "source": [
        "## Training-related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IlpRZU8c_-on"
      },
      "outputs": [],
      "source": [
        "def validate_epoch(model, val_dataloader, loss_function, num_classes, ignore_label):\n",
        "    model.eval()\n",
        "    batch_losses = []\n",
        "    metrics = {'miou': 0, 'loss': 0}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (inputs, targets) in val_dataloader:\n",
        "            ipts = torch.autograd.Variable(inputs).cuda()\n",
        "            tgts = torch.autograd.Variable(targets).cuda()\n",
        "            \n",
        "            preds = model(ipts)['out']\n",
        "            loss = loss_function(preds, tgts.squeeze(1).long())\n",
        "            loss = loss.data.cpu().numpy()\n",
        "            batch_losses += [loss]\n",
        "\n",
        "            preds = torch.argmax(preds.cpu(), dim=1)\n",
        "            tgts = torch.squeeze(targets, dim=1)\n",
        "\n",
        "            miou, ious = utils.measure_performance(preds, tgts, num_classes=num_classes, ignore_label=ignore_label)\n",
        "\n",
        "            metrics['miou'] += miou\n",
        "            metrics['loss'] += loss\n",
        "\n",
        "        metrics['miou'] /= float(len(val_dataloader))\n",
        "        metrics['loss'] /= float(len(val_dataloader))\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HCkzs16c_-oo"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_dataloader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    batch_losses = []\n",
        "    \n",
        "    for (inputs, targets) in train_dataloader:\n",
        "        ipts = torch.autograd.Variable(inputs).cuda()\n",
        "        tgts = torch.autograd.Variable(targets).cuda().squeeze(1).long()\n",
        "        pred = model(ipts)['out']\n",
        "\n",
        "        loss = loss_function(pred, tgts)\n",
        "        loss_val = loss.data.cpu().numpy()\n",
        "        batch_losses += [loss_val]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return batch_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BQIfP6W3_-oo"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataloader, val_dataloader, epochs, loss_function, optimizer, lr_initial, lr_decay, num_classes_val, ignore_label):\n",
        "    model.train()\n",
        "    epoch_train_losses = []\n",
        "    epoch_val_losses = []\n",
        "    epoch_val_mious = []\n",
        "    for epoch in tqdm(range(epochs), desc='Epoch progress'):\n",
        "        batch_train_losses = train_epoch(\n",
        "            model=model, \n",
        "            train_dataloader=train_dataloader,\n",
        "            loss_function=loss_function, \n",
        "            optimizer=optimizer)\n",
        "        \n",
        "        batch_val_metrics = validate_epoch(\n",
        "            model=model,\n",
        "            val_dataloader=val_dataloader,\n",
        "            loss_function=loss_function,\n",
        "            num_classes=num_classes_val,\n",
        "            ignore_label=ignore_label)\n",
        "\n",
        "        epoch_average_train_loss = np.mean(batch_train_losses)\n",
        "        epoch_train_losses += [epoch_average_train_loss]\n",
        "        epoch_val_losses += [batch_val_metrics['loss']]\n",
        "        epoch_val_mious += [batch_val_metrics['miou']]\n",
        "\n",
        "        print(f'\\n\\n[TRAIN] Epoch average loss: {epoch_average_train_loss:.2f}')\n",
        "        print(f'[VAL] Epoch average loss: {batch_val_metrics[\"loss\"]:.2f}')\n",
        "        print(f'[VAL] Epoch average miou: {batch_val_metrics[\"miou\"]:.2f}\\n')\n",
        "        \n",
        "        if lr_decay:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_initial * ((1.0 - (float(epoch) / float(epochs))) ** 0.9)\n",
        "\n",
        "    return {'epoch_train_losses': epoch_train_losses, 'epoch_val_losses': epoch_val_losses, 'epoch_val_mious': epoch_val_mious}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rc2ZjUV_-oo"
      },
      "source": [
        "## Training configuration loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q45lVAz2_-op",
        "outputId": "ed87cac9-6d68-4a33-9c9c-096a0a092c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data_batch_size': 4,\n",
            " 'data_source': 'real',\n",
            " 'data_subset_size': 1000,\n",
            " 'epochs': 20,\n",
            " 'fine_tune': False,\n",
            " 'fine_tune_path': 'G:/My Drive/Master IVA/Master Thesis/Models',\n",
            " 'ignore_label': 19,\n",
            " 'image_height': 256,\n",
            " 'image_width': 256,\n",
            " 'learning_rate': 0.0005,\n",
            " 'learning_rate_paper_decay': True,\n",
            " 'model_save_path': 'G:/My Drive/Master IVA/Master Thesis/Models',\n",
            " 'val_data_batch_size': 4,\n",
            " 'val_data_subset_size': 250}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "args = {}\n",
        "with open('G:/My Drive/Master IVA/Master Thesis/Configs/train-config-1.json') as json_file:\n",
        "    args = json.load(json_file)\n",
        "pprint.pprint(args)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l3c4vosw_-op"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "train_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=args[\"data_batch_size\"],\n",
        "                              shuffle=True)\n",
        "val_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                 type=args[\"data_source\"],\n",
        "                                 labels_mapping=None)\n",
        "val_dataset = Subset(val_dataset, indices=range(args[\"val_data_subset_size\"]))\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=args[\"val_data_batch_size\"],\n",
        "                            shuffle=True)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdJK3pF7RRKn",
        "outputId": "91ef22bf-48a8-43c4-acf3-6e9701143f6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training dataset norm. params. comp. progress: 100%|██████████| 250/250 [01:46<00:00,  2.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset 'mean':tensor([0.2529, 0.2962, 0.2568])\n",
            "Train dataset 'std deviation':tensor([0.1703, 0.1773, 0.1741])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation dataset norm. params. comp. progress:   0%|          | 0/63 [00:00<?, ?it/s]C:\\Users\\Manuel\\AppData\\Local\\Temp\\ipykernel_24092\\3029786214.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_inputs_tensor = torch.tensor(val_inputs)\n",
            "Validation dataset norm. params. comp. progress: 100%|██████████| 63/63 [00:26<00:00,  2.40it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation dataset 'mean':tensor([0.3294, 0.3618, 0.3221])\n",
            "Validation dataset 'std deviation':tensor([0.2062, 0.2059, 0.2016])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_pixel_sum = torch.tensor([0.0, 0.0, 0.0])\n",
        "train_pixel_sum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "for train_inputs, _ in tqdm(train_dataloader, desc='Training dataset norm. params. comp. progress'):\n",
        "    train_pixel_sum += train_inputs.sum(axis = [0, 2, 3])\n",
        "    train_pixel_sum_sq += (train_inputs ** 2).sum(axis = [0, 2, 3])\n",
        "\n",
        "train_pixel_count = args[\"data_subset_size\"] * args[\"image_width\"] * args[\"image_height\"]\n",
        "train_mean = train_pixel_sum / train_pixel_count\n",
        "train_variance = (train_pixel_sum_sq / train_pixel_count) - (train_mean ** 2)\n",
        "train_std = torch.sqrt(train_variance)\n",
        "\n",
        "print(f'Train dataset \\'mean\\':{train_mean}')\n",
        "print(f'Train dataset \\'std deviation\\':{train_std}')\n",
        "\n",
        "val_pixel_sum = torch.tensor([0.0, 0.0, 0.0])\n",
        "val_pixel_sum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "for val_inputs, _ in tqdm(val_dataloader, desc='Validation dataset norm. params. comp. progress'):\n",
        "    val_inputs_tensor = torch.tensor(val_inputs)\n",
        "    val_pixel_sum += val_inputs_tensor.sum(axis = [0, 2, 3])\n",
        "    val_pixel_sum_sq += (val_inputs_tensor ** 2).sum(axis = [0, 2, 3])\n",
        "\n",
        "val_pixel_count = args[\"val_data_subset_size\"] * args[\"image_width\"] * args[\"image_height\"]\n",
        "val_mean = val_pixel_sum / val_pixel_count\n",
        "val_variance = (val_pixel_sum_sq / val_pixel_count) - (val_mean ** 2)\n",
        "val_std = torch.sqrt(val_variance)\n",
        "\n",
        "print(f'Validation dataset \\'mean\\':{val_mean}')\n",
        "print(f'Validation dataset \\'std deviation\\':{val_std}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M8kQ9HkVRRKo"
      },
      "outputs": [],
      "source": [
        "train_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.Normalize(mean=list(train_mean), std=list(train_std))]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=args[\"data_batch_size\"],\n",
        "                              shuffle=True)\n",
        "val_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.Normalize(mean=list(val_mean), std=list(val_std))]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]), \n",
        "                                 type=args[\"data_source\"],\n",
        "                                 labels_mapping=None)\n",
        "val_dataset = Subset(val_dataset, indices=range(args[\"val_data_subset_size\"]))\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=args[\"val_data_batch_size\"],\n",
        "                            shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQIRQ39o_-op"
      },
      "source": [
        "## Training preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhR4VbF2_-op",
        "outputId": "f4675100-719a-425f-a436-2f27f3e405c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model to device.\n"
          ]
        }
      ],
      "source": [
        "model = dlv3.deeplabv3_resnet50(weights=None, output_stride=16, progress=True, num_classes=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys())-1)  \n",
        "if args[\"fine_tune\"]:\n",
        "    model.load_state_dict(torch.load(args[\"fine_tune_model_path\"]))\n",
        "    for name, param in model.backbone.named_parameters():\n",
        "        if 'layer1' in name or 'layer2' in name or 'layer3' in name or 'layer4' in name or 'layer5' in name:\n",
        "            print(f'---> Freezing layer: {name}.')\n",
        "            param.requires_grad = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('Loaded model to device.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ud3YI0lQ_-oq"
      },
      "outputs": [],
      "source": [
        "params = utils.add_weight_decay(model, l2_value=0.0001)\n",
        "optimizer = torch.optim.Adam(params=params, lr=args[\"learning_rate\"])\n",
        "loss_function = nn.CrossEntropyLoss(ignore_index=args[\"ignore_label\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VKyjxND_-oq",
        "outputId": "ac9f3984-73d5-47ed-9f42-a93c40938b73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   5%|▌         | 1/20 [02:31<47:56, 151.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.66\n",
            "[VAL] Epoch average loss: 0.71\n",
            "[VAL] Epoch average miou: 0.19\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  10%|█         | 2/20 [05:01<45:13, 150.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.50\n",
            "[VAL] Epoch average loss: 0.67\n",
            "[VAL] Epoch average miou: 0.21\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  15%|█▌        | 3/20 [07:39<43:33, 153.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.45\n",
            "[VAL] Epoch average loss: 0.72\n",
            "[VAL] Epoch average miou: 0.22\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  20%|██        | 4/20 [10:14<41:10, 154.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.42\n",
            "[VAL] Epoch average loss: 0.66\n",
            "[VAL] Epoch average miou: 0.22\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  25%|██▌       | 5/20 [12:48<38:36, 154.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.39\n",
            "[VAL] Epoch average loss: 0.62\n",
            "[VAL] Epoch average miou: 0.23\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  30%|███       | 6/20 [15:23<36:01, 154.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.36\n",
            "[VAL] Epoch average loss: 0.61\n",
            "[VAL] Epoch average miou: 0.23\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  35%|███▌      | 7/20 [18:05<33:59, 156.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.34\n",
            "[VAL] Epoch average loss: 0.57\n",
            "[VAL] Epoch average miou: 0.24\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  40%|████      | 8/20 [20:43<31:26, 157.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.34\n",
            "[VAL] Epoch average loss: 0.55\n",
            "[VAL] Epoch average miou: 0.25\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  45%|████▌     | 9/20 [23:36<29:43, 162.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.31\n",
            "[VAL] Epoch average loss: 0.53\n",
            "[VAL] Epoch average miou: 0.25\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  50%|█████     | 10/20 [26:14<26:49, 160.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.28\n",
            "[VAL] Epoch average loss: 0.52\n",
            "[VAL] Epoch average miou: 0.26\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  55%|█████▌    | 11/20 [28:52<24:00, 160.08s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.28\n",
            "[VAL] Epoch average loss: 0.51\n",
            "[VAL] Epoch average miou: 0.26\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  60%|██████    | 12/20 [31:31<21:17, 159.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.27\n",
            "[VAL] Epoch average loss: 0.53\n",
            "[VAL] Epoch average miou: 0.26\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  65%|██████▌   | 13/20 [34:08<18:32, 158.89s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.26\n",
            "[VAL] Epoch average loss: 0.52\n",
            "[VAL] Epoch average miou: 0.26\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  70%|███████   | 14/20 [37:00<16:17, 162.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.24\n",
            "[VAL] Epoch average loss: 0.52\n",
            "[VAL] Epoch average miou: 0.28\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  75%|███████▌  | 15/20 [39:41<13:32, 162.47s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.24\n",
            "[VAL] Epoch average loss: 0.53\n",
            "[VAL] Epoch average miou: 0.27\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  80%|████████  | 16/20 [42:21<10:46, 161.54s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.23\n",
            "[VAL] Epoch average loss: 0.51\n",
            "[VAL] Epoch average miou: 0.27\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  85%|████████▌ | 17/20 [44:59<08:01, 160.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.22\n",
            "[VAL] Epoch average loss: 0.53\n",
            "[VAL] Epoch average miou: 0.27\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  90%|█████████ | 18/20 [47:37<05:19, 159.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.21\n",
            "[VAL] Epoch average loss: 0.51\n",
            "[VAL] Epoch average miou: 0.27\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  95%|█████████▌| 19/20 [50:14<02:39, 159.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.20\n",
            "[VAL] Epoch average loss: 0.52\n",
            "[VAL] Epoch average miou: 0.27\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress: 100%|██████████| 20/20 [52:52<00:00, 158.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.19\n",
            "[VAL] Epoch average loss: 0.52\n",
            "[VAL] Epoch average miou: 0.27\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_metrics = train(model=model, \n",
        "      train_dataloader=train_dataloader, \n",
        "      val_dataloader=val_dataloader, \n",
        "      epochs=args[\"epochs\"], \n",
        "      loss_function=loss_function, \n",
        "      optimizer=optimizer, \n",
        "      lr_initial=args[\"learning_rate\"],\n",
        "      lr_decay=args[\"learning_rate_paper_decay\"],\n",
        "      num_classes_val=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys()),\n",
        "      ignore_label=args[\"ignore_label\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train report generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1sEVMrQz_-oq"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "current_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_save_path = f'{args[\"model_save_path\"]}/{current_time}'\n",
        "os.mkdir(model_save_path)\n",
        "\n",
        "plt.plot(train_metrics['epoch_train_losses'], label='Train loss', color='blue') \n",
        "plt.plot(train_metrics['epoch_val_losses'], label='Validation loss', color='yellow') \n",
        "plt.xlabel('Epoch') \n",
        "plt.ylabel('Loss') \n",
        "plt.xticks(range(0, args['epochs']))\n",
        "plt.title('Loss over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/loss_over_epochs.jpg', dpi=300)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(train_metrics['epoch_val_mious'], label='Validation mIoU', color='green') \n",
        "plt.xlabel('Epoch') \n",
        "plt.ylabel('mIoU') \n",
        "plt.xticks(range(0, args['epochs']))\n",
        "plt.title('mIoU over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/iou_over_epochs.jpg', dpi=300)\n",
        "\n",
        "args = json.dumps(args, indent=4)\n",
        "with open(file=f'{model_save_path}/train_config.json', mode='w') as f:\n",
        "    f.write(args)\n",
        "\n",
        "torch.save(model.state_dict(), f'{model_save_path}/deeplabv3_model.pt')\n",
        "playsound.playsound('finished.mp3')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
