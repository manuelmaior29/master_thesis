{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6RtFDqwe_-oh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import playsound\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.models.segmentation.deeplabv3 as dlv3\n",
        "import torchvision.transforms.functional as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import utils\n",
        "import data\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Subset\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAHxPFi3_-on"
      },
      "source": [
        "## Training-related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IlpRZU8c_-on"
      },
      "outputs": [],
      "source": [
        "def validate_epoch(model, val_dataloader, loss_function, num_classes, ignore_label):\n",
        "    model.eval()\n",
        "    batch_losses = []\n",
        "    metrics = {'miou': 0, 'loss': 0}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (inputs, targets) in val_dataloader:\n",
        "            ipts = torch.autograd.Variable(inputs).cuda()\n",
        "            tgts = torch.autograd.Variable(targets).cuda()\n",
        "            \n",
        "            preds = model(ipts)['out']\n",
        "            loss = loss_function(preds, tgts.squeeze(1).long())\n",
        "            loss = loss.data.cpu().numpy()\n",
        "            batch_losses += [loss]\n",
        "\n",
        "            preds = torch.argmax(preds.cpu(), dim=1)\n",
        "            tgts = torch.squeeze(targets, dim=1)\n",
        "\n",
        "            miou, ious = utils.measure_performance(preds, tgts, num_classes=num_classes, ignore_label=ignore_label)\n",
        "\n",
        "            metrics['miou'] += miou\n",
        "            metrics['loss'] += loss\n",
        "\n",
        "        metrics['miou'] /= float(len(val_dataloader))\n",
        "        metrics['loss'] /= float(len(val_dataloader))\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HCkzs16c_-oo"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, train_dataloader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    batch_losses = []\n",
        "    \n",
        "    for (inputs, targets) in train_dataloader:\n",
        "        ipts = torch.autograd.Variable(inputs).cuda()\n",
        "        tgts = torch.autograd.Variable(targets).cuda().squeeze(1).long()\n",
        "        pred = model(ipts)['out']\n",
        "\n",
        "        loss = loss_function(pred, tgts)\n",
        "        loss_val = loss.data.cpu().numpy()\n",
        "        batch_losses += [loss_val]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return batch_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BQIfP6W3_-oo"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataloader, val_dataloader, epochs, loss_function, optimizer, lr_initial, lr_decay, num_classes_val, ignore_label):\n",
        "    model.train()\n",
        "    epoch_train_losses = []\n",
        "    epoch_val_losses = []\n",
        "    epoch_val_mious = []\n",
        "    for epoch in tqdm(range(epochs), desc='Epoch progress'):\n",
        "        batch_train_losses = train_epoch(\n",
        "            model=model, \n",
        "            train_dataloader=train_dataloader,\n",
        "            loss_function=loss_function, \n",
        "            optimizer=optimizer)\n",
        "        \n",
        "        batch_val_metrics = validate_epoch(\n",
        "            model=model,\n",
        "            val_dataloader=val_dataloader,\n",
        "            loss_function=loss_function,\n",
        "            num_classes=num_classes_val,\n",
        "            ignore_label=ignore_label)\n",
        "\n",
        "        epoch_average_train_loss = np.mean(batch_train_losses)\n",
        "        epoch_train_losses += [epoch_average_train_loss]\n",
        "        epoch_val_losses += [batch_val_metrics['loss']]\n",
        "        epoch_val_mious += [batch_val_metrics['miou']]\n",
        "\n",
        "        print(f'\\n\\n[TRAIN] Epoch average loss: {epoch_average_train_loss:.2f}')\n",
        "        print(f'[VAL] Epoch average loss: {batch_val_metrics[\"loss\"]:.2f}')\n",
        "        print(f'[VAL] Epoch average miou: {batch_val_metrics[\"miou\"]:.2f}\\n')\n",
        "        \n",
        "        if lr_decay:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_initial * ((1.0 - (float(epoch) / float(epochs))) ** 0.9)\n",
        "\n",
        "    return {'epoch_train_losses': epoch_train_losses, 'epoch_val_losses': epoch_val_losses, 'epoch_val_mious': epoch_val_mious}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rc2ZjUV_-oo"
      },
      "source": [
        "## Training configuration loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q45lVAz2_-op",
        "outputId": "ed87cac9-6d68-4a33-9c9c-096a0a092c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data_batch_size': 4,\n",
            " 'data_source': 'synthetic',\n",
            " 'data_subset_size': 8,\n",
            " 'epochs': 8,\n",
            " 'fine_tune': False,\n",
            " 'fine_tune_path': 'G:/My Drive/Master IVA/Master Thesis/Models',\n",
            " 'ignore_label': 19,\n",
            " 'image_height': 256,\n",
            " 'image_width': 256,\n",
            " 'learning_rate': 0.0005,\n",
            " 'learning_rate_paper_decay': True,\n",
            " 'model_save_path': 'G:/My Drive/Master IVA/Master Thesis/Models',\n",
            " 'val_data_batch_size': 4,\n",
            " 'val_data_subset_size': 4}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "args = {}\n",
        "with open('G:/My Drive/Master IVA/Master Thesis/Configs/train-config-1.json') as json_file:\n",
        "    args = json.load(json_file)\n",
        "pprint.pprint(args)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l3c4vosw_-op"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "train_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=args[\"data_batch_size\"],\n",
        "                              shuffle=True)\n",
        "val_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                 type=args[\"data_source\"],\n",
        "                                 labels_mapping=None)\n",
        "val_dataset = Subset(val_dataset, indices=range(args[\"val_data_subset_size\"]))\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=args[\"val_data_batch_size\"],\n",
        "                            shuffle=True)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdJK3pF7RRKn",
        "outputId": "91ef22bf-48a8-43c4-acf3-6e9701143f6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training dataset norm. params. comp. progress: 100%|██████████| 2/2 [00:00<00:00,  2.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset 'mean':tensor([0.4125, 0.4055, 0.3984])\n",
            "Train dataset 'std deviation':tensor([0.2003, 0.1952, 0.1941])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation dataset norm. params. comp. progress:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\Manuel\\AppData\\Local\\Temp\\ipykernel_32644\\3029786214.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_inputs_tensor = torch.tensor(val_inputs)\n",
            "Validation dataset norm. params. comp. progress: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation dataset 'mean':tensor([0.3571, 0.3552, 0.3487])\n",
            "Validation dataset 'std deviation':tensor([0.2071, 0.2074, 0.2095])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_pixel_sum = torch.tensor([0.0, 0.0, 0.0])\n",
        "train_pixel_sum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "for train_inputs, _ in tqdm(train_dataloader, desc='Training dataset norm. params. comp. progress'):\n",
        "    train_pixel_sum += train_inputs.sum(axis = [0, 2, 3])\n",
        "    train_pixel_sum_sq += (train_inputs ** 2).sum(axis = [0, 2, 3])\n",
        "\n",
        "train_pixel_count = args[\"data_subset_size\"] * args[\"image_width\"] * args[\"image_height\"]\n",
        "train_mean = train_pixel_sum / train_pixel_count\n",
        "train_variance = (train_pixel_sum_sq / train_pixel_count) - (train_mean ** 2)\n",
        "train_std = torch.sqrt(train_variance)\n",
        "\n",
        "print(f'Train dataset \\'mean\\':{train_mean}')\n",
        "print(f'Train dataset \\'std deviation\\':{train_std}')\n",
        "\n",
        "val_pixel_sum = torch.tensor([0.0, 0.0, 0.0])\n",
        "val_pixel_sum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "for val_inputs, _ in tqdm(val_dataloader, desc='Validation dataset norm. params. comp. progress'):\n",
        "    val_inputs_tensor = torch.tensor(val_inputs)\n",
        "    val_pixel_sum += val_inputs_tensor.sum(axis = [0, 2, 3])\n",
        "    val_pixel_sum_sq += (val_inputs_tensor ** 2).sum(axis = [0, 2, 3])\n",
        "\n",
        "val_pixel_count = args[\"val_data_subset_size\"] * args[\"image_width\"] * args[\"image_height\"]\n",
        "val_mean = val_pixel_sum / val_pixel_count\n",
        "val_variance = (val_pixel_sum_sq / val_pixel_count) - (val_mean ** 2)\n",
        "val_std = torch.sqrt(val_variance)\n",
        "\n",
        "print(f'Validation dataset \\'mean\\':{val_mean}')\n",
        "print(f'Validation dataset \\'std deviation\\':{val_std}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M8kQ9HkVRRKo"
      },
      "outputs": [],
      "source": [
        "train_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.Normalize(mean=list(train_mean), std=list(train_std))]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=args[\"data_batch_size\"],\n",
        "                              shuffle=True)\n",
        "val_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.Normalize(mean=list(val_mean), std=list(val_std))]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]), \n",
        "                                 type=args[\"data_source\"],\n",
        "                                 labels_mapping=None)\n",
        "val_dataset = Subset(val_dataset, indices=range(args[\"val_data_subset_size\"]))\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=args[\"val_data_batch_size\"],\n",
        "                            shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQIRQ39o_-op"
      },
      "source": [
        "## Training preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhR4VbF2_-op",
        "outputId": "f4675100-719a-425f-a436-2f27f3e405c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model to device.\n"
          ]
        }
      ],
      "source": [
        "model = dlv3.deeplabv3_resnet50(weights=None, output_stride=16, progress=True, num_classes=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys()))  \n",
        "if args[\"fine_tune\"]:\n",
        "    model.load_state_dict(torch.load(args[\"fine_tune_model_path\"]))\n",
        "    for name, param in model.backbone.named_parameters():\n",
        "        if 'layer1' in name or 'layer2' in name or 'layer3' in name or 'layer4' in name or 'layer5' in name:\n",
        "            print(f'---> Freezing layer: {name}.')\n",
        "            param.requires_grad = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('Loaded model to device.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ud3YI0lQ_-oq"
      },
      "outputs": [],
      "source": [
        "params = utils.add_weight_decay(model, l2_value=0.0001)\n",
        "optimizer = torch.optim.Adam(params=params, lr=args[\"learning_rate\"])\n",
        "loss_function = nn.CrossEntropyLoss()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VKyjxND_-oq",
        "outputId": "ac9f3984-73d5-47ed-9f42-a93c40938b73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  12%|█▎        | 1/8 [00:04<00:28,  4.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 2.59\n",
            "[VAL] Epoch average loss: 2.57\n",
            "[VAL] Epoch average miou: 0.08\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  25%|██▌       | 2/8 [00:05<00:14,  2.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 1.56\n",
            "[VAL] Epoch average loss: 1.94\n",
            "[VAL] Epoch average miou: 0.10\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  38%|███▊      | 3/8 [00:06<00:09,  1.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 1.11\n",
            "[VAL] Epoch average loss: 1.58\n",
            "[VAL] Epoch average miou: 0.11\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  50%|█████     | 4/8 [00:08<00:06,  1.73s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.91\n",
            "[VAL] Epoch average loss: 1.39\n",
            "[VAL] Epoch average miou: 0.13\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  62%|██████▎   | 5/8 [00:09<00:04,  1.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.83\n",
            "[VAL] Epoch average loss: 1.24\n",
            "[VAL] Epoch average miou: 0.13\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  75%|███████▌  | 6/8 [00:10<00:02,  1.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.76\n",
            "[VAL] Epoch average loss: 1.15\n",
            "[VAL] Epoch average miou: 0.13\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  88%|████████▊ | 7/8 [00:12<00:01,  1.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.71\n",
            "[VAL] Epoch average loss: 1.09\n",
            "[VAL] Epoch average miou: 0.13\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress: 100%|██████████| 8/8 [00:13<00:00,  1.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[TRAIN] Epoch average loss: 0.69\n",
            "[VAL] Epoch average loss: 1.05\n",
            "[VAL] Epoch average miou: 0.14\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_metrics = train(model=model, \n",
        "      train_dataloader=train_dataloader, \n",
        "      val_dataloader=val_dataloader, \n",
        "      epochs=args[\"epochs\"], \n",
        "      loss_function=loss_function, \n",
        "      optimizer=optimizer, \n",
        "      lr_initial=args[\"learning_rate\"],\n",
        "      lr_decay=args[\"learning_rate_paper_decay\"],\n",
        "      num_classes_val=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys()),\n",
        "      ignore_label=None)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train report generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1sEVMrQz_-oq"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Object of type Tensor is not JSON serializable",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Manuel\\Projects\\GitHub_Repositories\\master_thesis\\python_scripts_semseg\\train.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X23sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m plt\u001b[39m.\u001b[39msavefig(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_save_path\u001b[39m}\u001b[39;00m\u001b[39m/iou_over_epochs.jpg\u001b[39m\u001b[39m'\u001b[39m, dpi\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m eval_args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mmodel_load_folder_path\u001b[39m\u001b[39m'\u001b[39m: model_save_path,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mtrain_std\u001b[39m\u001b[39m'\u001b[39m: train_std,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mtrain_mean\u001b[39m\u001b[39m'\u001b[39m: train_mean,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X23sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mimage_width\u001b[39m\u001b[39m'\u001b[39m: args[\u001b[39m'\u001b[39m\u001b[39mimage_width\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X23sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mimage_height\u001b[39m\u001b[39m'\u001b[39m: args[\u001b[39m'\u001b[39m\u001b[39mimage_height\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X23sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m eval_args \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mdumps(eval_args, indent\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X23sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_save_path\u001b[39m}\u001b[39;00m\u001b[39m/eval-config.json\u001b[39m\u001b[39m'\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Manuel/Projects/GitHub_Repositories/master_thesis/python_scripts_semseg/train.ipynb#X23sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     f\u001b[39m.\u001b[39mwrite(eval_args)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\json\\__init__.py:234\u001b[0m, in \u001b[0;36mdumps\u001b[1;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONEncoder\n\u001b[1;32m--> 234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[0;32m    235\u001b[0m     skipkeys\u001b[39m=\u001b[39;49mskipkeys, ensure_ascii\u001b[39m=\u001b[39;49mensure_ascii,\n\u001b[0;32m    236\u001b[0m     check_circular\u001b[39m=\u001b[39;49mcheck_circular, allow_nan\u001b[39m=\u001b[39;49mallow_nan, indent\u001b[39m=\u001b[39;49mindent,\n\u001b[0;32m    237\u001b[0m     separators\u001b[39m=\u001b[39;49mseparators, default\u001b[39m=\u001b[39;49mdefault, sort_keys\u001b[39m=\u001b[39;49msort_keys,\n\u001b[0;32m    238\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\u001b[39m.\u001b[39;49mencode(obj)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\json\\encoder.py:201\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    199\u001b[0m chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miterencode(o, _one_shot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(chunks, (\u001b[39mlist\u001b[39m, \u001b[39mtuple\u001b[39m)):\n\u001b[1;32m--> 201\u001b[0m     chunks \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(chunks)\n\u001b[0;32m    202\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(chunks)\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\json\\encoder.py:431\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[0;32m    430\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(o, \u001b[39mdict\u001b[39m):\n\u001b[1;32m--> 431\u001b[0m     \u001b[39myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[0;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\json\\encoder.py:405\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m             chunks \u001b[39m=\u001b[39m _iterencode(value, _current_indent_level)\n\u001b[1;32m--> 405\u001b[0m         \u001b[39myield from\u001b[39;00m chunks\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m newline_indent \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    407\u001b[0m     _current_indent_level \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\json\\encoder.py:438\u001b[0m, in \u001b[0;36m_make_iterencode.<locals>._iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCircular reference detected\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    437\u001b[0m     markers[markerid] \u001b[39m=\u001b[39m o\n\u001b[1;32m--> 438\u001b[0m o \u001b[39m=\u001b[39m _default(o)\n\u001b[0;32m    439\u001b[0m \u001b[39myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[0;32m    440\u001b[0m \u001b[39mif\u001b[39;00m markers \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\json\\encoder.py:179\u001b[0m, in \u001b[0;36mJSONEncoder.default\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault\u001b[39m(\u001b[39mself\u001b[39m, o):\n\u001b[0;32m    161\u001b[0m     \u001b[39m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \n\u001b[0;32m    178\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mObject of type \u001b[39m\u001b[39m{\u001b[39;00mo\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    180\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mis not JSON serializable\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[1;31mTypeError\u001b[0m: Object of type Tensor is not JSON serializable"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "current_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_save_path = f'{args[\"model_save_path\"]}/{current_time}'\n",
        "os.mkdir(model_save_path)\n",
        "\n",
        "plt.plot(train_metrics['epoch_train_losses'], label='Train loss', color='blue') \n",
        "plt.plot(train_metrics['epoch_val_losses'], label='Validation loss', color='yellow') \n",
        "plt.xlabel('Epoch') \n",
        "plt.ylabel('Loss') \n",
        "plt.xticks(range(0, args['epochs']))\n",
        "plt.title('Loss over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/loss_over_epochs.jpg', dpi=300)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(train_metrics['epoch_val_mious'], label='Validation mIoU', color='green') \n",
        "plt.xlabel('Epoch') \n",
        "plt.ylabel('mIoU') \n",
        "plt.xticks(range(0, args['epochs']))\n",
        "plt.title('mIoU over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/iou_over_epochs.jpg', dpi=300)\n",
        "\n",
        "eval_args = {'model_load_folder_path': model_save_path,\n",
        "             'train_std': train_std,\n",
        "             'train_mean': train_mean,\n",
        "             'data_source': \"real\",\n",
        "             'test_subset_size': 300,\n",
        "             'test_batch_size': 4,\n",
        "             'ignore_label': args['ignore_label'],\n",
        "             'image_width': args['image_width'],\n",
        "             'image_height': args['image_height']}\n",
        "eval_args = json.dumps(eval_args, indent=4)\n",
        "with open(file=f'{model_save_path}/eval-config.json', mode='w') as f:\n",
        "    f.write(eval_args)\n",
        "    \n",
        "args = json.dumps(args, indent=4)\n",
        "with open(file=f'{model_save_path}/train_config.json', mode='w') as f:\n",
        "    f.write(args)\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), f'{model_save_path}/deeplabv3_model.pt')\n",
        "playsound.playsound('finished.mp3')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
