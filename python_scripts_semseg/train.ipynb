{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "6RtFDqwe_-oh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.models.segmentation.deeplabv3 as dlv3\n",
        "import torchvision.transforms.functional as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import utils\n",
        "import data\n",
        "import copy\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAHxPFi3_-on"
      },
      "source": [
        "## Training-related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "IlpRZU8c_-on"
      },
      "outputs": [],
      "source": [
        "def validate_epoch(model, device, val_dataloader, loss_function, num_classes, ignore_label):\n",
        "    model.eval()\n",
        "    metrics = {'miou': 0, 'ious': np.zeros(shape=(num_classes,), dtype=np.float64), 'loss': 0}\n",
        "    confusion_mat = np.zeros(shape=(num_classes, num_classes), dtype=np.int64)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for (inputs, targets) in val_dataloader:\n",
        "            ipts = inputs.to(device, non_blocking=True)# torch.autograd.Variable(inputs).cuda()\n",
        "            tgts = targets.to(device, non_blocking=True)# torch.autograd.Variable(targets).cuda()\n",
        "            \n",
        "            preds = model(ipts)['out']\n",
        "            loss = loss_function(preds, tgts.squeeze(1).long())\n",
        "            loss_val = loss.item()\n",
        "\n",
        "            preds = torch.argmax(preds.cpu(), dim=1)\n",
        "            tgts = torch.squeeze(targets, dim=1)\n",
        "\n",
        "            confusion_mat = np.add(confusion_mat, utils.compute_confusion_matrix(predictions=preds, targets=tgts, num_classes=num_classes))\n",
        "            metrics['loss'] += loss_val\n",
        "\n",
        "        miou, ious = utils.measure_performance(confusion_mat=confusion_mat,\n",
        "                                               num_classes=num_classes,\n",
        "                                               ignore_label=ignore_label)\n",
        "        \n",
        "        metrics['ious'] = ious\n",
        "        metrics['miou'] = miou\n",
        "        metrics['loss'] /= float(len(val_dataloader))\n",
        "        \n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "HCkzs16c_-oo"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, device, scaler, train_dataloader, loss_function, num_classes, optimizer, compute_iou=False):\n",
        "    model.train()\n",
        "    metrics = {'miou': 0, 'ious': np.zeros(shape=(num_classes,), dtype=np.float64), 'loss': 0}\n",
        "    \n",
        "    for (inputs, targets) in train_dataloader:\n",
        "        ipts = inputs.to(device, non_blocking=True)# torch.autograd.Variable(inputs).cuda()\n",
        "        tgts = targets.to(device, non_blocking=True).squeeze(1).long() #tgts = torch.autograd.Variable(targets).cuda().squeeze(1).long()\n",
        "        \n",
        "        pred = model(ipts)['out']\n",
        "        with torch.cuda.amp.autocast():\n",
        "            loss = loss_function(pred, tgts)\n",
        "            loss_val = loss.item()\n",
        "            metrics['loss'] += loss_val\n",
        "\n",
        "        # Measure miou on training\n",
        "        if compute_iou:\n",
        "            pred = torch.argmax(pred.cpu(), dim=1)\n",
        "            tgts = torch.squeeze(targets, dim=1)\n",
        "            miou, ious = utils.measure_performance(pred, tgts, num_classes=num_classes, ignore_label=None)\n",
        "            metrics['ious'] += ious\n",
        "            metrics['miou'] += miou\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        scaler.scale(loss).backward() # loss.backward()\n",
        "        scaler.step(optimizer) #optimizer.step()\n",
        "        scaler.update()\n",
        "    \n",
        "    if compute_iou:\n",
        "        metrics['ious'] /= float(len(train_dataloader))\n",
        "        metrics['miou'] /= float(len(train_dataloader))\n",
        "\n",
        "    metrics['loss'] /= float(len(train_dataloader))\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "BQIfP6W3_-oo"
      },
      "outputs": [],
      "source": [
        "def train(model, device, scaler, train_dataloader, val_dataloader, epochs, loss_function, optimizer, lr_initial, lr_decay, num_classes_val, ignore_label):\n",
        "    model.train()\n",
        "    compute_iou = False\n",
        "\n",
        "    epoch_train_losses = []\n",
        "    epoch_train_mious = []\n",
        "    epoch_val_losses = []\n",
        "    epoch_val_mious = []\n",
        "    epoch_val_ious = []\n",
        "\n",
        "    best_model = copy.deepcopy(model.state_dict())\n",
        "    best_val_miou = 0\n",
        "    \n",
        "    for epoch in tqdm(range(epochs), desc='Epoch progress'):\n",
        "\n",
        "        # Training phase\n",
        "        batch_train_metrics = train_epoch(\n",
        "            model=model, \n",
        "            device=device,\n",
        "            scaler=scaler,\n",
        "            train_dataloader=train_dataloader,\n",
        "            loss_function=loss_function,\n",
        "            num_classes=num_classes_val,\n",
        "            optimizer=optimizer,\n",
        "            compute_iou=compute_iou)\n",
        "        \n",
        "        # Validation phase\n",
        "        batch_val_metrics = validate_epoch(\n",
        "            model=model,\n",
        "            device=device,\n",
        "            val_dataloader=val_dataloader,\n",
        "            loss_function=loss_function,\n",
        "            num_classes=num_classes_val,\n",
        "            ignore_label=ignore_label)\n",
        "\n",
        "        epoch_train_losses += [batch_train_metrics[\"loss\"]]\n",
        "        epoch_val_losses += [batch_val_metrics['loss']]\n",
        "        epoch_val_mious += [batch_val_metrics['miou']]\n",
        "        epoch_val_ious += [batch_val_metrics['ious'].tolist()]\n",
        "\n",
        "        print(f'\\n[TRAIN] Epoch average loss: {batch_train_metrics[\"loss\"]:.4f}')\n",
        "        if compute_iou:\n",
        "            epoch_train_mious += [batch_train_metrics[\"miou\"]]\n",
        "            print(f'[TRAIN] Epoch average miou: {100 * batch_train_metrics[\"miou\"]:.2f}%')\n",
        "        print(f'[VAL] Epoch average loss: {batch_val_metrics[\"loss\"]:.4f}')\n",
        "        print(f'[VAL] Epoch average miou: {100 * batch_val_metrics[\"miou\"]:.2f}%')\n",
        "        \n",
        "        if lr_decay:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_initial * ((1.0 - (float(epoch) / float(epochs))) ** 0.9)\n",
        "\n",
        "        if epoch == 0 or batch_val_metrics['miou'] > best_val_miou:\n",
        "            best_val_miou = batch_val_metrics['miou']\n",
        "            best_model = copy.deepcopy(model.state_dict())\n",
        "            print('\\033[96m[MODEL] Checkpoint saved.\\n\\033[0m')\n",
        "\n",
        "    model.load_state_dict(best_model)\n",
        "    return model, {'epoch_train_losses': epoch_train_losses, 'epoch_val_losses': epoch_val_losses, 'epoch_val_mious': epoch_val_mious, 'epoch_val_ious': epoch_val_ious}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rc2ZjUV_-oo"
      },
      "source": [
        "## Training configuration loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q45lVAz2_-op",
        "outputId": "ed87cac9-6d68-4a33-9c9c-096a0a092c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data_batch_size': 12,\n",
            " 'data_source': 'real',\n",
            " 'data_stat_mean': None,\n",
            " 'data_stat_std': [0.2868727445602417, 0.3250778019428253, 0.28385287523269653],\n",
            " 'data_subset_size': 2973,\n",
            " 'epochs': 2,\n",
            " 'fine_tune': False,\n",
            " 'fine_tune_model_path': 'G:/My Drive/Master IVA/Master '\n",
            "                         'Thesis/Models/20230409_211303/deeplabv3_model.pt',\n",
            " 'ignore_label': 19,\n",
            " 'image_height': 256,\n",
            " 'image_width': 512,\n",
            " 'learning_rate': 0.007,\n",
            " 'learning_rate_paper_decay': True,\n",
            " 'model_folder_suffix': 'real_train_check',\n",
            " 'model_save_path': 'G:/My Drive/Master IVA/Master Thesis/Models',\n",
            " 'val_data_batch_size': 4,\n",
            " 'val_data_subset_size': 8,\n",
            " 'weighted_loss': False}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "args = {}\n",
        "with open('G:/My Drive/Master IVA/Master Thesis/Configs/train-config-1.json') as json_file:\n",
        "    args = json.load(json_file)\n",
        "pprint.pprint(args)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "l3c4vosw_-op"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training dataset norm. params. comp. progress: 100%|██████████| 248/248 [06:06<00:00,  1.48s/it]\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "\n",
        "train_mean = None\n",
        "train_std = None\n",
        "\n",
        "if args['data_stat_mean'] is not None and args['data_stat_std'] is not None:\n",
        "\ttrain_std = torch.tensor(args['data_stat_std'])\n",
        "\ttrain_mean = torch.tensor(args['data_stat_mean'])\n",
        "else:\n",
        "\ttrain_dataset = data.HybridDataset(root_path=f'E:/Datasets/{args[\"data_source\"]}/train',\n",
        "\t\t\t\t\t\t\t\t\tinput_dir='rgb',\n",
        "\t\t\t\t\t\t\t\t\ttarget_dir='semantic_segmentation_mapped',\n",
        "\t\t\t\t\t\t\t\t\tipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "\t\t\t\t\t\t\t\t\ttgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "\t\t\t\t\t\t\t\t\tlabels_mapping=None,\n",
        "\t\t\t\t\t\t\t\t\ttype=args[\"data_source\"])\n",
        "\ttrain_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "\ttrain_dataloader = DataLoader(dataset=train_dataset,\n",
        "\t\t\t\t\t\t\tbatch_size=args[\"data_batch_size\"],\n",
        "\t\t\t\t\t\t\tshuffle=True)\n",
        "\n",
        "\ttrain_pixel_sum = 0 #torch.tensor([0.0, 0.0, 0.0])\n",
        "\ttrain_pixel_sum_sq = 0 #torch.tensor([0.0, 0.0, 0.0])\n",
        "\tnum_batches = 0\n",
        "\tfor train_inputs, _ in tqdm(train_dataloader, desc='Training dataset norm. params. comp. progress'):\n",
        "\t\ttrain_pixel_sum += torch.mean(train_inputs, dim=[0, 2, 3]) #train_inputs.sum(axis = [0, 2, 3])\n",
        "\t\ttrain_pixel_sum_sq += torch.mean(train_inputs**2, dim=[0, 2, 3]) #(train_inputs ** 2).sum(axis = [0, 2, 3])\n",
        "\t\tnum_batches += 1\n",
        "\n",
        "\t# train_pixel_count = args[\"data_subset_size\"] * args[\"image_width\"] * args[\"image_height\"]\n",
        "\ttrain_mean = train_pixel_sum / num_batches\n",
        "\ttrain_std = (train_pixel_sum_sq / num_batches - train_mean**2)**0.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset 'mean':tensor([0.2869, 0.3252, 0.2839])\n",
            "Train dataset 'std deviation':tensor([0.1864, 0.1897, 0.1867])\n"
          ]
        }
      ],
      "source": [
        "print(f'Train dataset \\'mean\\':{train_mean}')\n",
        "print(f'Train dataset \\'std deviation\\':{train_std}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "M8kQ9HkVRRKo"
      },
      "outputs": [],
      "source": [
        "# Datasets\n",
        "## Train dataset\n",
        "train_dataset = data.HybridDataset(root_path=f'E:/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.Normalize(mean=list(train_mean), std=list(train_std)),\n",
        "                                                                                 torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "\n",
        "## Train dataset (aug)\n",
        "train_dataset_aug = data.HybridDataset(root_path=f'E:/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.Normalize(mean=list(train_mean), std=list(train_std)),\n",
        "                                                                                 torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset_aug = Subset(train_dataset_aug, indices=range(args[\"data_subset_size\"]))\n",
        "\n",
        "## Val dataset\n",
        "val_dataset = data.HybridDataset(root_path=f'E:/Datasets/real/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.Normalize(mean=list(train_mean), std=list(train_std)),\n",
        "                                                                               torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.RandomHorizontalFlip(p=1.0)]), \n",
        "                                 type='real',\n",
        "                                 labels_mapping=None)\n",
        "val_dataset = Subset(val_dataset, indices=range(args[\"val_data_subset_size\"]))\n",
        "\n",
        "## Val dataset (aug)\n",
        "val_dataset_aug = data.HybridDataset(root_path=f'E:/Datasets/real/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.Normalize(mean=list(train_mean), std=list(train_std)),\n",
        "                                                                               torchvision.transforms.RandomHorizontalFlip(p=1.0)]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.RandomHorizontalFlip(p=1.0)]), \n",
        "                                 type='real',\n",
        "                                 labels_mapping=None)\n",
        "val_dataset_aug = Subset(val_dataset_aug, indices=range(args[\"val_data_subset_size\"]))\n",
        "\n",
        "# Concatenate original + aug datasets\n",
        "train_dataset_concatenated = ConcatDataset([train_dataset, train_dataset_aug])\n",
        "val_dataset_concatenated = ConcatDataset([val_dataset, val_dataset_aug])\n",
        "\n",
        "# Dataloaders\n",
        "train_dataloader = DataLoader(dataset=train_dataset_concatenated,\n",
        "                              batch_size=args[\"data_batch_size\"],\n",
        "                              shuffle=True, pin_memory=True, num_workers=4)\n",
        "val_dataloader = DataLoader(dataset=val_dataset_concatenated,\n",
        "                            batch_size=args[\"val_data_batch_size\"],\n",
        "                            shuffle=True, pin_memory=True, num_workers=4)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zQIRQ39o_-op"
      },
      "source": [
        "## Training preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhR4VbF2_-op",
        "outputId": "f4675100-719a-425f-a436-2f27f3e405c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model to device.\n",
            "DeepLabV3(\n",
            "  (backbone): IntermediateLayerGetter(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (classifier): DeepLabHead(\n",
            "    (0): ASPP(\n",
            "      (convs): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (1): ASPPConv(\n",
            "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (2): ASPPConv(\n",
            "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (3): ASPPConv(\n",
            "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU()\n",
            "        )\n",
            "        (4): ASPPPooling(\n",
            "          (0): AdaptiveAvgPool2d(output_size=1)\n",
            "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (3): ReLU()\n",
            "        )\n",
            "      )\n",
            "      (project): Sequential(\n",
            "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Dropout(p=0.5, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(256, 17, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = dlv3.deeplabv3_resnet50(weights=None, output_stride=16, progress=True, num_classes=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys()))\n",
        "if args[\"fine_tune\"]:\n",
        "    print('\\033[96m[MODEL] Fine-tuning.\\n\\033[0m')\n",
        "    model.load_state_dict(torch.load(args[\"fine_tune_model_path\"]))\n",
        "    for name, param in model.backbone.named_parameters():\n",
        "        if 'layer1' in name or 'layer2' in name or 'layer3' in name or 'layer4' in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('Loaded model to device.')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Ud3YI0lQ_-oq"
      },
      "outputs": [],
      "source": [
        "params = utils.add_weight_decay(model, l2_value=0.0001)\n",
        "optimizer = torch.optim.Adam(params=params, lr=args[\"learning_rate\"])\n",
        "\n",
        "class_weights = None\n",
        "if args['weighted_loss']:\n",
        "    if args['data_source'] == 'synthetic':\n",
        "        class_weights = [\n",
        "                (100 - 34.547) / 100,\n",
        "                (100 - 7.025) / 100,\n",
        "                (100 - 16.881) / 100,\n",
        "                (100 - 1.842) / 100,\n",
        "                (100 - 0.698) / 100,\n",
        "                (100 - 0.109) / 100,\n",
        "                (100 - 0.139) / 100,\n",
        "                (100 - 13.758) / 100,\n",
        "                (100 - 1.368) / 100,\n",
        "                (100 - 0.925) / 100,\n",
        "                (100 - 0.104) / 100,\n",
        "                (100 - 3.03) / 100,\n",
        "                (100 - 1.504) / 100,\n",
        "                (100 - 0.789) / 100,\n",
        "                (100 - 0.087) / 100,\n",
        "                (100 - 0.017) / 100,\n",
        "                (100 - 17.177) / 100,\n",
        "            ]\n",
        "    elif args['data_source'] == 'real':\n",
        "        class_weights = [\n",
        "                (100 - 32.635) / 100,\n",
        "                (100 - 5.39) / 100,\n",
        "                (100 - 20.203) / 100,\n",
        "                (100 - 0.58) / 100,\n",
        "                (100 - 0.777) / 100,\n",
        "                (100 - 0.184) / 100,\n",
        "                (100 - 0.488) / 100,\n",
        "                (100 - 14.104) / 100,\n",
        "                (100 - 1.021) / 100,\n",
        "                (100 - 1.08) / 100,\n",
        "                (100 - 0.12) / 100,\n",
        "                (100 - 6.195) / 100,\n",
        "                (100 - 0.237) / 100,\n",
        "                (100 - 0.208) / 100,\n",
        "                (100 - 0.087) / 100,\n",
        "                (100 - 0.367) / 100,\n",
        "                (100 - 16.324) / 100,\n",
        "            ]\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).to(device)) if args['weighted_loss'] else nn.CrossEntropyLoss()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VKyjxND_-oq",
        "outputId": "ac9f3984-73d5-47ed-9f42-a93c40938b73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   0%|          | 0/2 [02:38<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[61], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mcudnn\u001b[39m.\u001b[39mbenchmark \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m      2\u001b[0m scaler \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mGradScaler()\n\u001b[1;32m----> 3\u001b[0m model, train_metrics \u001b[39m=\u001b[39m train(model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m      4\u001b[0m                              device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m      5\u001b[0m                              scaler\u001b[39m=\u001b[39;49mscaler,\n\u001b[0;32m      6\u001b[0m                              train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader, \n\u001b[0;32m      7\u001b[0m                              val_dataloader\u001b[39m=\u001b[39;49mval_dataloader, \n\u001b[0;32m      8\u001b[0m                              epochs\u001b[39m=\u001b[39;49margs[\u001b[39m\"\u001b[39;49m\u001b[39mepochs\u001b[39;49m\u001b[39m\"\u001b[39;49m], \n\u001b[0;32m      9\u001b[0m                              loss_function\u001b[39m=\u001b[39;49mloss_function, \n\u001b[0;32m     10\u001b[0m                              optimizer\u001b[39m=\u001b[39;49moptimizer, \n\u001b[0;32m     11\u001b[0m                              lr_initial\u001b[39m=\u001b[39;49margs[\u001b[39m\"\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     12\u001b[0m                              lr_decay\u001b[39m=\u001b[39;49margs[\u001b[39m\"\u001b[39;49m\u001b[39mlearning_rate_paper_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     13\u001b[0m                              num_classes_val\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(data\u001b[39m.\u001b[39;49mSemanticLabelMapper\u001b[39m.\u001b[39;49mID_TO_STRING[\u001b[39m'\u001b[39;49m\u001b[39mcommon\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mkeys()),\n\u001b[0;32m     14\u001b[0m                              ignore_label\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n",
            "Cell \u001b[1;32mIn[54], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, device, scaler, train_dataloader, val_dataloader, epochs, loss_function, optimizer, lr_initial, lr_decay, num_classes_val, ignore_label)\u001b[0m\n\u001b[0;32m     12\u001b[0m best_val_miou \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs), desc\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch progress\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m     \u001b[39m# Training phase\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     batch_train_metrics \u001b[39m=\u001b[39m train_epoch(\n\u001b[0;32m     18\u001b[0m         model\u001b[39m=\u001b[39;49mmodel, \n\u001b[0;32m     19\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m     20\u001b[0m         scaler\u001b[39m=\u001b[39;49mscaler,\n\u001b[0;32m     21\u001b[0m         train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[0;32m     22\u001b[0m         loss_function\u001b[39m=\u001b[39;49mloss_function,\n\u001b[0;32m     23\u001b[0m         num_classes\u001b[39m=\u001b[39;49mnum_classes_val,\n\u001b[0;32m     24\u001b[0m         optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m     25\u001b[0m         compute_iou\u001b[39m=\u001b[39;49mcompute_iou)\n\u001b[0;32m     27\u001b[0m     \u001b[39m# Validation phase\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     batch_val_metrics \u001b[39m=\u001b[39m validate_epoch(\n\u001b[0;32m     29\u001b[0m         model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     30\u001b[0m         device\u001b[39m=\u001b[39mdevice,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m         num_classes\u001b[39m=\u001b[39mnum_classes_val,\n\u001b[0;32m     34\u001b[0m         ignore_label\u001b[39m=\u001b[39mignore_label)\n",
            "Cell \u001b[1;32mIn[53], line 5\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, device, scaler, train_dataloader, loss_function, num_classes, optimizer, compute_iou)\u001b[0m\n\u001b[0;32m      2\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      3\u001b[0m metrics \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mmiou\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mious\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mzeros(shape\u001b[39m=\u001b[39m(num_classes,), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64), \u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m}\n\u001b[1;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m (inputs, targets) \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[0;32m      6\u001b[0m     ipts \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m# torch.autograd.Variable(inputs).cuda()\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     tgts \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device, non_blocking\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mlong() \u001b[39m#tgts = torch.autograd.Variable(targets).cuda().squeeze(1).long()\u001b[39;00m\n",
            "File \u001b[1;32me:\\Software\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32me:\\Software\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1356\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[0;32m   1358\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m-> 1359\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[0;32m   1360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[0;32m   1362\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
            "File \u001b[1;32me:\\Software\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1315\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1313\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m   1314\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_thread\u001b[39m.\u001b[39mis_alive():\n\u001b[1;32m-> 1315\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[0;32m   1316\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[0;32m   1317\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[1;32me:\\Software\\anaconda\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1163\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1151\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1152\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1161\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1162\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1163\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m   1164\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[0;32m   1165\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1166\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
            "File \u001b[1;32me:\\Software\\anaconda\\lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[39mif\u001b[39;00m remaining \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnot_empty\u001b[39m.\u001b[39;49mwait(remaining)\n\u001b[0;32m    181\u001b[0m item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnot_full\u001b[39m.\u001b[39mnotify()\n",
            "File \u001b[1;32me:\\Software\\anaconda\\lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39;49macquire(\u001b[39mTrue\u001b[39;49;00m, timeout)\n\u001b[0;32m    325\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[39m=\u001b[39m waiter\u001b[39m.\u001b[39macquire(\u001b[39mFalse\u001b[39;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "model, train_metrics = train(model=model,\n",
        "                             device=device,\n",
        "                             scaler=scaler,\n",
        "                             train_dataloader=train_dataloader, \n",
        "                             val_dataloader=val_dataloader, \n",
        "                             epochs=args[\"epochs\"], \n",
        "                             loss_function=loss_function, \n",
        "                             optimizer=optimizer, \n",
        "                             lr_initial=args[\"learning_rate\"],\n",
        "                             lr_decay=args[\"learning_rate_paper_decay\"],\n",
        "                             num_classes_val=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys()),\n",
        "                             ignore_label=None)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train report generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sEVMrQz_-oq"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "current_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_save_path = f'{args[\"model_save_path\"]}/{current_time}_{args[\"model_folder_suffix\"]}'\n",
        "os.mkdir(model_save_path)\n",
        "\n",
        "matplotlib.rcParams.update({'font.size': 6})\n",
        "\n",
        "plt.plot(train_metrics['epoch_train_losses'], label='Train loss', color='blue') \n",
        "plt.plot(train_metrics['epoch_val_losses'], label='Validation loss', color='yellow') \n",
        "plt.xlabel('Epoch') \n",
        "plt.xticks(ticks=np.arange(0, args['epochs']))\n",
        "plt.ylabel('Loss') \n",
        "plt.title('Loss over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/loss_over_epochs.jpg', dpi=1200)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(train_metrics['epoch_val_mious'], label='Validation mIoU', color='green') \n",
        "plt.xlabel('Epoch') \n",
        "plt.xticks(ticks=np.arange(0, args['epochs']))\n",
        "plt.ylabel('mIoU') \n",
        "plt.yticks(np.arange(0.0, 1.1, 0.1))\n",
        "plt.title('mIoU over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/iou_over_epochs.jpg', dpi=1200)\n",
        "\n",
        "train_std = train_std.tolist()\n",
        "train_mean = train_mean.tolist()\n",
        "\n",
        "eval_args = {'model_load_folder_path': model_save_path,\n",
        "             'train_std': train_std,\n",
        "             'train_mean': train_mean,\n",
        "             'data_source': \"real\",\n",
        "             'test_subset_size': 200,\n",
        "             'test_batch_size': 1,\n",
        "             'ignore_label': args['ignore_label'],\n",
        "             'image_width': args['image_width'],\n",
        "             'image_height': args['image_height']}\n",
        "eval_args = json.dumps(eval_args, indent=4)\n",
        "with open(file=f'{model_save_path}/eval-config.json', mode='w') as f:\n",
        "    f.write(eval_args)\n",
        "    \n",
        "args = json.dumps(args, indent=4)\n",
        "with open(file=f'{model_save_path}/train_config.json', mode='w') as f:\n",
        "    f.write(args)\n",
        "\n",
        "train_metrics = json.dumps(train_metrics, indent=4)\n",
        "with open(file=f'{model_save_path}/train_metrics.json', mode='w') as f:\n",
        "    f.write(train_metrics)\n",
        "\n",
        "torch.save(model.state_dict(), f'{model_save_path}/deeplabv3_model.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
