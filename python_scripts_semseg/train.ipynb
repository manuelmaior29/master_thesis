{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6RtFDqwe_-oh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import playsound\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.models.segmentation.deeplabv3 as dlv3\n",
        "import torchvision.transforms.functional as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import utils\n",
        "import data\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Subset\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAHxPFi3_-on"
      },
      "source": [
        "## Training-related functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IlpRZU8c_-on"
      },
      "outputs": [],
      "source": [
        "def validate_epoch(model, device, val_dataloader, loss_function, num_classes, ignore_label):\n",
        "    model.eval()\n",
        "    batch_losses = []\n",
        "    metrics = {'miou': 0, 'ious': [], 'loss': 0}\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for (inputs, targets) in val_dataloader:\n",
        "            start_time = time.time()\n",
        "            ipts = inputs.to(device, non_blocking=True)# torch.autograd.Variable(inputs).cuda()\n",
        "            tgts = targets.to(device, non_blocking=True)# torch.autograd.Variable(targets).cuda()\n",
        "            \n",
        "            preds = model(ipts)['out']\n",
        "            loss = loss_function(preds, tgts.squeeze(1).long())\n",
        "            loss_val = loss.item()\n",
        "            batch_losses += [loss_val]\n",
        "\n",
        "            preds = torch.argmax(preds.cpu(), dim=1)\n",
        "            tgts = torch.squeeze(targets, dim=1)\n",
        "\n",
        "            miou, ious = utils.measure_performance(preds, tgts, num_classes=num_classes, ignore_label=ignore_label)\n",
        "\n",
        "            metrics['miou'] += miou\n",
        "            metrics['loss'] += loss\n",
        "            \n",
        "            print(f'Batch validation time: {time.time() - start_time:.5f} s')\n",
        "\n",
        "        metrics['miou'] /= float(len(val_dataloader))\n",
        "        metrics['loss'] /= float(len(val_dataloader))\n",
        "        \n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HCkzs16c_-oo"
      },
      "outputs": [],
      "source": [
        "def train_epoch(model, device, train_dataloader, loss_function, optimizer):\n",
        "    model.train()\n",
        "    batch_losses = []\n",
        "    \n",
        "    for (inputs, targets) in train_dataloader:\n",
        "        start_time = time.time()\n",
        "        ipts = inputs.to(device, non_blocking=True)# torch.autograd.Variable(inputs).cuda()\n",
        "        tgts = targets.to(device, non_blocking=True).squeeze(1).long() #tgts = torch.autograd.Variable(targets).cuda().squeeze(1).long()\n",
        "        pred = model(ipts)['out']\n",
        "\n",
        "        loss = loss_function(pred, tgts)\n",
        "        loss_val = loss.item()\n",
        "        batch_losses += [loss_val]\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        print(f'Batch training time: {time.time() - start_time:.5f} s')\n",
        "    return batch_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BQIfP6W3_-oo"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_dataloader, val_dataloader, epochs, loss_function, optimizer, lr_initial, lr_decay, num_classes_val, ignore_label):\n",
        "    model.train()\n",
        "    epoch_train_losses = []\n",
        "    epoch_val_losses = []\n",
        "    epoch_val_mious = []\n",
        "    for epoch in tqdm(range(epochs), desc='Epoch progress'):\n",
        "\n",
        "        # Training phase\n",
        "        batch_train_losses = train_epoch(\n",
        "            model=model, \n",
        "            device=device,\n",
        "            train_dataloader=train_dataloader,\n",
        "            loss_function=loss_function, \n",
        "            optimizer=optimizer)\n",
        "        \n",
        "        # Validation phase\n",
        "        batch_val_metrics = validate_epoch(\n",
        "            model=model,\n",
        "            device=device,\n",
        "            val_dataloader=val_dataloader,\n",
        "            loss_function=loss_function,\n",
        "            num_classes=num_classes_val,\n",
        "            ignore_label=ignore_label)\n",
        "\n",
        "        epoch_average_train_loss = np.mean(batch_train_losses)\n",
        "        epoch_train_losses += [epoch_average_train_loss]\n",
        "        epoch_val_losses += [batch_val_metrics['loss']]\n",
        "        epoch_val_mious += [batch_val_metrics['miou']]\n",
        "\n",
        "        print(f'\\n[TRAIN] Epoch average loss: {epoch_average_train_loss:.2f}')\n",
        "        print(f'[VAL] Epoch average loss: {batch_val_metrics[\"loss\"]:.2f}')\n",
        "        print(f'[VAL] Epoch average miou: {batch_val_metrics[\"miou\"]:.2f}\\n')\n",
        "        \n",
        "        if lr_decay:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_initial * ((1.0 - (float(epoch) / float(epochs))) ** 0.9)\n",
        "\n",
        "    return {'epoch_train_losses': epoch_train_losses, 'epoch_val_losses': epoch_val_losses, 'epoch_val_mious': epoch_val_mious}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rc2ZjUV_-oo"
      },
      "source": [
        "## Training configuration loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q45lVAz2_-op",
        "outputId": "ed87cac9-6d68-4a33-9c9c-096a0a092c82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'data_batch_size': 8,\n",
            " 'data_source': 'real',\n",
            " 'data_subset_size': 80,\n",
            " 'epochs': 8,\n",
            " 'fine_tune': False,\n",
            " 'fine_tune_model_path': 'G:/My Drive/Master IVA/Master '\n",
            "                         'Thesis/Models/20230403_210427/deeplabv3_model.pt',\n",
            " 'ignore_label': 19,\n",
            " 'image_height': 256,\n",
            " 'image_width': 256,\n",
            " 'learning_rate': 0.0005,\n",
            " 'learning_rate_paper_decay': True,\n",
            " 'model_save_path': 'G:/My Drive/Master IVA/Master Thesis/Models',\n",
            " 'val_data_batch_size': 8,\n",
            " 'val_data_subset_size': 24}\n"
          ]
        }
      ],
      "source": [
        "import pprint\n",
        "args = {}\n",
        "with open('G:/My Drive/Master IVA/Master Thesis/Configs/train-config-2.json') as json_file:\n",
        "    args = json.load(json_file)\n",
        "pprint.pprint(args)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l3c4vosw_-op"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "train_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=args[\"data_batch_size\"],\n",
        "                              shuffle=True)\n",
        "val_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                 type=args[\"data_source\"],\n",
        "                                 labels_mapping=None)\n",
        "val_dataset = Subset(val_dataset, indices=range(args[\"val_data_subset_size\"]))\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=args[\"val_data_batch_size\"],\n",
        "                            shuffle=True)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdJK3pF7RRKn",
        "outputId": "91ef22bf-48a8-43c4-acf3-6e9701143f6f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training dataset norm. params. comp. progress: 100%|██████████| 10/10 [00:08<00:00,  1.16it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset 'mean':tensor([0.2344, 0.2750, 0.2347])\n",
            "Train dataset 'std deviation':tensor([0.1429, 0.1525, 0.1484])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Validation dataset norm. params. comp. progress:   0%|          | 0/3 [00:00<?, ?it/s]C:\\Users\\Manuel\\AppData\\Local\\Temp\\ipykernel_2820\\3029786214.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_inputs_tensor = torch.tensor(val_inputs)\n",
            "Validation dataset norm. params. comp. progress: 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation dataset 'mean':tensor([0.3364, 0.3708, 0.3299])\n",
            "Validation dataset 'std deviation':tensor([0.2168, 0.2167, 0.2151])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_pixel_sum = torch.tensor([0.0, 0.0, 0.0])\n",
        "train_pixel_sum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "for train_inputs, _ in tqdm(train_dataloader, desc='Training dataset norm. params. comp. progress'):\n",
        "    train_pixel_sum += train_inputs.sum(axis = [0, 2, 3])\n",
        "    train_pixel_sum_sq += (train_inputs ** 2).sum(axis = [0, 2, 3])\n",
        "\n",
        "train_pixel_count = args[\"data_subset_size\"] * args[\"image_width\"] * args[\"image_height\"]\n",
        "train_mean = train_pixel_sum / train_pixel_count\n",
        "train_variance = (train_pixel_sum_sq / train_pixel_count) - (train_mean ** 2)\n",
        "train_std = torch.sqrt(train_variance)\n",
        "\n",
        "print(f'Train dataset \\'mean\\':{train_mean}')\n",
        "print(f'Train dataset \\'std deviation\\':{train_std}')\n",
        "\n",
        "val_pixel_sum = torch.tensor([0.0, 0.0, 0.0])\n",
        "val_pixel_sum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
        "\n",
        "for val_inputs, _ in tqdm(val_dataloader, desc='Validation dataset norm. params. comp. progress'):\n",
        "    val_inputs_tensor = torch.tensor(val_inputs)\n",
        "    val_pixel_sum += val_inputs_tensor.sum(axis = [0, 2, 3])\n",
        "    val_pixel_sum_sq += (val_inputs_tensor ** 2).sum(axis = [0, 2, 3])\n",
        "\n",
        "val_pixel_count = args[\"val_data_subset_size\"] * args[\"image_width\"] * args[\"image_height\"]\n",
        "val_mean = val_pixel_sum / val_pixel_count\n",
        "val_variance = (val_pixel_sum_sq / val_pixel_count) - (val_mean ** 2)\n",
        "val_std = torch.sqrt(val_variance)\n",
        "\n",
        "print(f'Validation dataset \\'mean\\':{val_mean}')\n",
        "print(f'Validation dataset \\'std deviation\\':{val_std}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "M8kQ9HkVRRKo"
      },
      "outputs": [],
      "source": [
        "train_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/train',\n",
        "                                   input_dir='rgb',\n",
        "                                   target_dir='semantic_segmentation_mapped',\n",
        "                                   ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                                 torchvision.transforms.Normalize(mean=list(train_mean), std=list(train_std))]),\n",
        "                                   tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]),\n",
        "                                   type=args[\"data_source\"],\n",
        "                                   labels_mapping=None)\n",
        "train_dataset = Subset(train_dataset, indices=range(args[\"data_subset_size\"]))\n",
        "train_dataloader = DataLoader(dataset=train_dataset,\n",
        "                              batch_size=args[\"data_batch_size\"],\n",
        "                              shuffle=True, pin_memory=True, num_workers=4)\n",
        "val_dataset = data.HybridDataset(root_path=f'G:/My Drive/Master IVA/Master Thesis/Datasets/{args[\"data_source\"]}/val',\n",
        "                                 input_dir='rgb',\n",
        "                                 target_dir='semantic_segmentation_mapped',\n",
        "                                 ipt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"])),\n",
        "                                                                               torchvision.transforms.Normalize(mean=list(val_mean), std=list(val_std))]),\n",
        "                                 tgt_transform=torchvision.transforms.Compose([torchvision.transforms.Resize((args[\"image_height\"], args[\"image_width\"]))]), \n",
        "                                 type=args[\"data_source\"],\n",
        "                                 labels_mapping=None)\n",
        "val_dataset = Subset(val_dataset, indices=range(args[\"val_data_subset_size\"]))\n",
        "val_dataloader = DataLoader(dataset=val_dataset,\n",
        "                            batch_size=args[\"val_data_batch_size\"],\n",
        "                            shuffle=True, pin_memory=True, num_workers=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQIRQ39o_-op"
      },
      "source": [
        "## Training preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhR4VbF2_-op",
        "outputId": "f4675100-719a-425f-a436-2f27f3e405c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model to device.\n"
          ]
        }
      ],
      "source": [
        "model = dlv3.deeplabv3_resnet50(weights=None, output_stride=16, progress=True, num_classes=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys()))\n",
        "if args[\"fine_tune\"]:\n",
        "    model.load_state_dict(torch.load(args[\"fine_tune_model_path\"]))\n",
        "    for name, param in model.backbone.named_parameters():\n",
        "        if 'layer1' in name or 'layer2' in name or 'layer3' in name or 'layer4' in name or 'layer5' in name:\n",
        "            param.requires_grad = False\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print('Loaded model to device.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Ud3YI0lQ_-oq"
      },
      "outputs": [],
      "source": [
        "params = utils.add_weight_decay(model, l2_value=0.0001)\n",
        "optimizer = torch.optim.Adam(params=params, lr=args[\"learning_rate\"])\n",
        "loss_function = nn.CrossEntropyLoss()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VKyjxND_-oq",
        "outputId": "ac9f3984-73d5-47ed-9f42-a93c40938b73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:   0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch training time: 0.45050 s\n",
            "Batch training time: 0.28806 s\n",
            "Batch training time: 0.28507 s\n",
            "Batch training time: 0.28706 s\n",
            "Batch training time: 0.28106 s\n",
            "Batch training time: 0.29007 s\n",
            "Batch training time: 0.29107 s\n",
            "Batch training time: 0.28414 s\n",
            "Batch training time: 0.29106 s\n",
            "Batch training time: 0.28606 s\n",
            "Batch validation time: 0.44910 s\n",
            "Batch validation time: 0.18304 s\n",
            "Batch validation time: 0.17515 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  12%|█▎        | 1/8 [00:11<01:17, 11.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 1.42\n",
            "[VAL] Epoch average loss: 1.06\n",
            "[VAL] Epoch average miou: 0.15\n",
            "\n",
            "Batch training time: 0.40127 s\n",
            "Batch training time: 0.29907 s\n",
            "Batch training time: 0.27806 s\n",
            "Batch training time: 0.28716 s\n",
            "Batch training time: 0.27706 s\n",
            "Batch training time: 0.28906 s\n",
            "Batch training time: 0.28907 s\n",
            "Batch training time: 0.28506 s\n",
            "Batch training time: 0.28604 s\n",
            "Batch training time: 0.28806 s\n",
            "Batch validation time: 0.44310 s\n",
            "Batch validation time: 0.18004 s\n",
            "Batch validation time: 0.17504 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  25%|██▌       | 2/8 [00:22<01:06, 11.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.81\n",
            "[VAL] Epoch average loss: 0.94\n",
            "[VAL] Epoch average miou: 0.19\n",
            "\n",
            "Batch training time: 0.28807 s\n",
            "Batch training time: 0.30839 s\n",
            "Batch training time: 0.28406 s\n",
            "Batch training time: 0.28907 s\n",
            "Batch training time: 0.27806 s\n",
            "Batch training time: 0.28806 s\n",
            "Batch training time: 0.28807 s\n",
            "Batch training time: 0.28606 s\n",
            "Batch training time: 0.28606 s\n",
            "Batch training time: 0.29107 s\n",
            "Batch validation time: 0.36008 s\n",
            "Batch validation time: 0.18204 s\n",
            "Batch validation time: 0.17704 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch progress:  38%|███▊      | 3/8 [00:32<00:54, 10.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[TRAIN] Epoch average loss: 0.67\n",
            "[VAL] Epoch average loss: 0.89\n",
            "[VAL] Epoch average miou: 0.19\n",
            "\n",
            "Batch training time: 0.36708 s\n",
            "Batch training time: 0.30607 s\n",
            "Batch training time: 0.28907 s\n",
            "Batch training time: 0.28938 s\n",
            "Batch training time: 0.28406 s\n",
            "Batch training time: 0.28606 s\n",
            "Batch training time: 0.28707 s\n"
          ]
        }
      ],
      "source": [
        "torch.backends.cudnn.benchmark = True\n",
        "train_metrics = train(model=model,\n",
        "                      device=device,\n",
        "                      train_dataloader=train_dataloader, \n",
        "                      val_dataloader=val_dataloader, \n",
        "                      epochs=args[\"epochs\"], \n",
        "                      loss_function=loss_function, \n",
        "                      optimizer=optimizer, \n",
        "                      lr_initial=args[\"learning_rate\"],\n",
        "                      lr_decay=args[\"learning_rate_paper_decay\"],\n",
        "                      num_classes_val=len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys()),\n",
        "                      ignore_label=None)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train report generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sEVMrQz_-oq"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "current_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_save_path = f'{args[\"model_save_path\"]}/{current_time}'\n",
        "os.mkdir(model_save_path)\n",
        "\n",
        "plt.plot(train_metrics['epoch_train_losses'], label='Train loss', color='blue') \n",
        "plt.plot(train_metrics['epoch_val_losses'], label='Validation loss', color='yellow') \n",
        "plt.xlabel('Epoch') \n",
        "plt.ylabel('Loss') \n",
        "plt.xticks(range(0, args['epochs']))\n",
        "plt.title('Loss over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/loss_over_epochs.jpg', dpi=300)\n",
        "\n",
        "plt.clf()\n",
        "plt.plot(train_metrics['epoch_val_mious'], label='Validation mIoU', color='green') \n",
        "plt.xlabel('Epoch') \n",
        "plt.ylabel('mIoU') \n",
        "plt.xticks(range(0, args['epochs']))\n",
        "plt.title('mIoU over Epochs') \n",
        "plt.legend()\n",
        "plt.savefig(f'{model_save_path}/iou_over_epochs.jpg', dpi=300)\n",
        "\n",
        "train_std = train_std.tolist()\n",
        "train_mean = train_mean.tolist()\n",
        "\n",
        "eval_args = {'model_load_folder_path': model_save_path,\n",
        "             'train_std': train_std,\n",
        "             'train_mean': train_mean,\n",
        "             'data_source': args['data_source'],\n",
        "             'test_subset_size': 300,\n",
        "             'test_batch_size': 4,\n",
        "             'ignore_label': args['ignore_label'],\n",
        "             'image_width': args['image_width'],\n",
        "             'image_height': args['image_height']}\n",
        "eval_args = json.dumps(eval_args, indent=4)\n",
        "with open(file=f'{model_save_path}/eval-config.json', mode='w') as f:\n",
        "    f.write(eval_args)\n",
        "    \n",
        "args = json.dumps(args, indent=4)\n",
        "with open(file=f'{model_save_path}/train_config.json', mode='w') as f:\n",
        "    f.write(args)\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), f'{model_save_path}/deeplabv3_model.pt')\n",
        "playsound.playsound('finished.mp3')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
