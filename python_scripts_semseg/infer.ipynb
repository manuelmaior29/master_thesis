{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models.segmentation.deeplabv3 as dlv3\n",
    "import torchvision.transforms.functional as tf\n",
    "import numpy as np\n",
    "import data\n",
    "import utils\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_prediction(input_image, pred_image, label_color_map, label_string_map):\n",
    "    label_legend_col = []\n",
    "\n",
    "    \n",
    "    # for i in range(len(label_color_map)):\n",
    "    #     color = label_color_map.values()[i] + [255]\n",
    "    #     color = np.array(color, dtype=np.float32)\n",
    "    #     color /= 255.0\n",
    "    #     label_legend_col.append(color.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters_load_path = r'G:/My Drive/Master IVA/Master Thesis/Models/20230321_211512/deeplabv3_model.pt'\n",
    "    \n",
    "ipt_path = r'G:\\My Drive\\Master IVA\\Master Thesis\\Datasets\\real\\test\\rgb\\real_rgb_3.png'\n",
    "tgt_path = r'G:\\My Drive\\Master IVA\\Master Thesis\\Datasets\\real\\test\\semantic_segmentation_mapped\\real_semantic_segmentation_3.png'\n",
    "\n",
    "num_classes = len(data.SemanticLabelMapper.ID_TO_STRING['common'].keys())\n",
    "infer_width_resize = 128\n",
    "infer_height_resize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model to device.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = dlv3.deeplabv3_resnet50(pretrained=False, progress=True, num_classes=num_classes-1)\n",
    "model.load_state_dict(torch.load(model_parameters_load_path))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print('Loaded model to device.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_ipt = Image.open(f'{ipt_path}', mode='r')\n",
    "transform = torchvision.transforms.Resize((infer_height_resize, infer_width_resize))\n",
    "ipt = tf.to_tensor(np.array(pil_ipt).astype(np.float32))\n",
    "ipt = transform(ipt).unsqueeze(0).to(device)\n",
    "\n",
    "pil_tgt = Image.open(f'{tgt_path}', mode='r')\n",
    "transform = torchvision.transforms.Resize((infer_height_resize, infer_width_resize))\n",
    "tgt = tf.to_tensor(np.array(pil_tgt).astype(np.float32)).long()\n",
    "tgt = transform(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU: 0.03394677047082526\n",
      "IoUs: [0.5866205020403116, 1.4142968466562504e-18, 4.467698288230007e-19, 2.2204460492503132e-17, 1.5105075164968116e-18, 1.982541115402065e-18, 2.0185873175002845e-18, 4.440892098500626e-18, 5.337610695313253e-20, 1.3061447348531253e-17, 0.05836813690536824, 2.362176648138631e-18, 1.586032892321652e-17, 9.83368489481981e-20, 1.2335811384723961e-17, 0, 5.551115123125783e-17, 0, 7.401486830834377e-17, 0]\n"
     ]
    }
   ],
   "source": [
    "ignore_label = 19\n",
    "with torch.no_grad():\n",
    "    input_image = pil_ipt.resize(size=(infer_width_resize, infer_width_resize), resample=Image.Resampling.BILINEAR)\n",
    "    \n",
    "    pred = model(ipt)['out']\n",
    "    pred = pred.data.cpu()[0]\n",
    "    pred = np.argmax(pred, axis=0).unsqueeze(0)\n",
    "    \n",
    "    miou, ious = utils.measure_performance(predictions=pred, targets=tgt, num_classes=num_classes, ignore_label=ignore_label)\n",
    "\n",
    "    print(f'Mean IoU: {miou}')\n",
    "    print(f'IoUs: {ious}')\n",
    "    \n",
    "    show_prediction(input_image=input_image, \n",
    "                    pred_image=pred.squeeze(0).numpy(), \n",
    "                    label_color_map=data.SemanticLabelMapper.ID_TO_COLOR['common'],\n",
    "                    label_string_map=data.SemanticLabelMapper.ID_TO_STRING['common'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
